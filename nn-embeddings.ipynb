{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10089847,"sourceType":"datasetVersion","datasetId":6221550}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport torch\nimport pandas as pd\nfrom transformers import BertTokenizer, BertModel\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score\nimport ast","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T21:35:51.312811Z","iopub.execute_input":"2024-12-05T21:35:51.313472Z","iopub.status.idle":"2024-12-05T21:36:08.873111Z","shell.execute_reply.started":"2024-12-05T21:35:51.313431Z","shell.execute_reply":"2024-12-05T21:36:08.872236Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load the BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nembedding_model = BertModel.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T21:37:28.019090Z","iopub.execute_input":"2024-12-05T21:37:28.019935Z","iopub.status.idle":"2024-12-05T21:37:31.594118Z","shell.execute_reply.started":"2024-12-05T21:37:28.019900Z","shell.execute_reply":"2024-12-05T21:37:31.593461Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a855b3b3ef8471ca88bce9a30bac930"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95da241a465248ba90b830e93c9c5ff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c67601d6efe942b796639f8632c7783d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d8a4c2bb8841d1a533724597eb42fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"382670df57ab49b6a2ac2f1f1c396a29"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# Train Preprocessing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nn-text-classfication/train.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Discussion'] = df['Discussion'].fillna('No Text')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf['Discussion'] = df['Discussion'].apply(replace_dates)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 50\ntotal_samples = len(df)  \n\nembedding_data = []\n\nstart_idx = 8500\n\nfor idx in range(start_idx, total_samples, batch_size):\n    end_idx = min(idx + batch_size, total_samples)\n    batch = df.iloc[idx:end_idx]\n\n    for index, row in batch.iterrows():\n        text = row['Discussion']\n\n        inputs = tokenizer(text, padding='max_length', truncation=True, return_tensors='pt', max_length=512)\n\n        with torch.no_grad():\n            outputs = embedding_model(**inputs)\n            last_hidden_states = outputs.last_hidden_state\n\n        sentence_embedding = last_hidden_states.mean(dim=1).squeeze().tolist()\n\n        embedding_data.append({\n            'SampleID': row['SampleID'],\n            'Category': row['Category'],\n            'Sentence_Embedding': sentence_embedding\n        })\n\n    embedding_df = pd.DataFrame(embedding_data)\n\n    embedding_df.to_csv('/kaggle/working/second_batch_embeddings.csv', index=False)\n    \n    print(f\"Finished processing {end_idx} samples.\")\n\nprint(f\"Processing completed for {total_samples} samples.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_first = pd.read_csv('/kaggle/input/embeddings-1/kaggle_first_batch_embeddings.csv')  # First dataset\ndf_second = pd.read_csv('/kaggle/input/second-embeddings/second_batch_embeddings.csv')  # Second dataset\n\ndf_combined = pd.concat([df_first, df_second], ignore_index=True)\n\n# Save the combined dataset to a new CSV\ndf_combined.to_csv('/kaggle/working/Final_BERT_Embeddings_NN.csv', index=False)\n\nprint(\"Datasets have been successfully combined and saved to 'Final_BERT_Embeddings_NN.csv'.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test Preprocessing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nn-text-classfication/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T21:36:14.639799Z","iopub.execute_input":"2024-12-05T21:36:14.640128Z","iopub.status.idle":"2024-12-05T21:36:14.744437Z","shell.execute_reply.started":"2024-12-05T21:36:14.640102Z","shell.execute_reply":"2024-12-05T21:36:14.743555Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T21:36:18.499022Z","iopub.execute_input":"2024-12-05T21:36:18.499353Z","iopub.status.idle":"2024-12-05T21:36:18.515212Z","shell.execute_reply.started":"2024-12-05T21:36:18.499325Z","shell.execute_reply":"2024-12-05T21:36:18.514497Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   SampleID                                         Discussion\n0         1  Managing cash flow effectively is crucial for ...\n1         2  Civic engagement plays a key role in a democra...\n2         3  Proper warm-ups and cool-downs are essential t...\n3         4  Data security is a growing concern as more peo...\n4         5  Investing in stocks can be risky, but with car...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Discussion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Managing cash flow effectively is crucial for ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Civic engagement plays a key role in a democra...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Proper warm-ups and cool-downs are essential t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Data security is a growing concern as more peo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Investing in stocks can be risky, but with car...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Fill NaN\ndf['Discussion'] = df['Discussion'].fillna('No Text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T21:36:20.772140Z","iopub.execute_input":"2024-12-05T21:36:20.772709Z","iopub.status.idle":"2024-12-05T21:36:20.778822Z","shell.execute_reply.started":"2024-12-05T21:36:20.772676Z","shell.execute_reply":"2024-12-05T21:36:20.777969Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf['Discussion'] = df['Discussion'].apply(replace_dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T21:36:22.857572Z","iopub.execute_input":"2024-12-05T21:36:22.857942Z","iopub.status.idle":"2024-12-05T21:36:23.028134Z","shell.execute_reply.started":"2024-12-05T21:36:22.857913Z","shell.execute_reply":"2024-12-05T21:36:23.027423Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"batch_size = 50\ntotal_samples = len(df)  \n\nembedding_data = []\n\nstart_idx = 0\n\nfor idx in range(start_idx, total_samples, batch_size):\n    end_idx = min(idx + batch_size, total_samples)\n    batch = df.iloc[idx:end_idx]\n\n    for index, row in batch.iterrows():\n        text = row['Discussion']\n\n        inputs = tokenizer(text, padding='max_length', truncation=True, return_tensors='pt', max_length=512)\n\n        with torch.no_grad():\n            outputs = embedding_model(**inputs)\n            last_hidden_states = outputs.last_hidden_state\n\n        sentence_embedding = last_hidden_states.mean(dim=1).squeeze().tolist()\n\n        embedding_data.append({\n            'SampleID': row['SampleID'],\n            'Sentence_Embedding': sentence_embedding\n        })\n\n    embedding_df = pd.DataFrame(embedding_data)\n\n    embedding_df.to_csv('/kaggle/working/second_batch_embeddings.csv', index=False)\n    \n    print(f\"Finished processing {end_idx} samples.\")\n\nprint(f\"Processing completed for {total_samples} samples.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T21:38:04.790065Z","iopub.execute_input":"2024-12-05T21:38:04.790962Z","iopub.status.idle":"2024-12-05T23:15:19.407629Z","shell.execute_reply.started":"2024-12-05T21:38:04.790928Z","shell.execute_reply":"2024-12-05T23:15:19.406700Z"}},"outputs":[{"name":"stdout","text":"Finished processing 50 samples.\nFinished processing 100 samples.\nFinished processing 150 samples.\nFinished processing 200 samples.\nFinished processing 250 samples.\nFinished processing 300 samples.\nFinished processing 350 samples.\nFinished processing 400 samples.\nFinished processing 450 samples.\nFinished processing 500 samples.\nFinished processing 550 samples.\nFinished processing 600 samples.\nFinished processing 650 samples.\nFinished processing 700 samples.\nFinished processing 750 samples.\nFinished processing 800 samples.\nFinished processing 850 samples.\nFinished processing 900 samples.\nFinished processing 950 samples.\nFinished processing 1000 samples.\nFinished processing 1050 samples.\nFinished processing 1100 samples.\nFinished processing 1150 samples.\nFinished processing 1200 samples.\nFinished processing 1250 samples.\nFinished processing 1300 samples.\nFinished processing 1350 samples.\nFinished processing 1400 samples.\nFinished processing 1450 samples.\nFinished processing 1500 samples.\nFinished processing 1550 samples.\nFinished processing 1600 samples.\nFinished processing 1650 samples.\nFinished processing 1700 samples.\nFinished processing 1750 samples.\nFinished processing 1800 samples.\nFinished processing 1850 samples.\nFinished processing 1900 samples.\nFinished processing 1950 samples.\nFinished processing 2000 samples.\nFinished processing 2050 samples.\nFinished processing 2100 samples.\nFinished processing 2150 samples.\nFinished processing 2200 samples.\nFinished processing 2250 samples.\nFinished processing 2300 samples.\nFinished processing 2350 samples.\nFinished processing 2400 samples.\nFinished processing 2450 samples.\nFinished processing 2500 samples.\nFinished processing 2550 samples.\nFinished processing 2600 samples.\nFinished processing 2650 samples.\nFinished processing 2700 samples.\nFinished processing 2750 samples.\nFinished processing 2800 samples.\nFinished processing 2850 samples.\nFinished processing 2900 samples.\nFinished processing 2950 samples.\nFinished processing 3000 samples.\nFinished processing 3050 samples.\nFinished processing 3100 samples.\nFinished processing 3150 samples.\nFinished processing 3200 samples.\nFinished processing 3250 samples.\nFinished processing 3300 samples.\nFinished processing 3350 samples.\nFinished processing 3400 samples.\nFinished processing 3450 samples.\nFinished processing 3500 samples.\nFinished processing 3550 samples.\nFinished processing 3600 samples.\nFinished processing 3650 samples.\nFinished processing 3700 samples.\nFinished processing 3750 samples.\nFinished processing 3800 samples.\nFinished processing 3850 samples.\nFinished processing 3900 samples.\nFinished processing 3950 samples.\nFinished processing 4000 samples.\nFinished processing 4050 samples.\nFinished processing 4100 samples.\nFinished processing 4150 samples.\nFinished processing 4200 samples.\nFinished processing 4250 samples.\nFinished processing 4300 samples.\nFinished processing 4350 samples.\nFinished processing 4400 samples.\nFinished processing 4450 samples.\nFinished processing 4500 samples.\nFinished processing 4550 samples.\nFinished processing 4600 samples.\nFinished processing 4650 samples.\nFinished processing 4700 samples.\nFinished processing 4750 samples.\nFinished processing 4800 samples.\nFinished processing 4850 samples.\nFinished processing 4900 samples.\nFinished processing 4950 samples.\nFinished processing 5000 samples.\nFinished processing 5050 samples.\nFinished processing 5100 samples.\nFinished processing 5150 samples.\nFinished processing 5200 samples.\nFinished processing 5250 samples.\nFinished processing 5300 samples.\nFinished processing 5350 samples.\nFinished processing 5400 samples.\nFinished processing 5450 samples.\nFinished processing 5500 samples.\nFinished processing 5550 samples.\nFinished processing 5600 samples.\nFinished processing 5650 samples.\nFinished processing 5700 samples.\nFinished processing 5750 samples.\nFinished processing 5800 samples.\nFinished processing 5850 samples.\nFinished processing 5900 samples.\nFinished processing 5950 samples.\nFinished processing 6000 samples.\nFinished processing 6050 samples.\nFinished processing 6100 samples.\nFinished processing 6150 samples.\nFinished processing 6200 samples.\nFinished processing 6250 samples.\nFinished processing 6300 samples.\nFinished processing 6350 samples.\nFinished processing 6400 samples.\nFinished processing 6450 samples.\nFinished processing 6500 samples.\nFinished processing 6550 samples.\nFinished processing 6600 samples.\nFinished processing 6650 samples.\nFinished processing 6700 samples.\nFinished processing 6750 samples.\nFinished processing 6800 samples.\nFinished processing 6850 samples.\nFinished processing 6900 samples.\nFinished processing 6950 samples.\nFinished processing 7000 samples.\nFinished processing 7050 samples.\nFinished processing 7100 samples.\nFinished processing 7150 samples.\nFinished processing 7200 samples.\nFinished processing 7250 samples.\nFinished processing 7300 samples.\nFinished processing 7350 samples.\nFinished processing 7400 samples.\nFinished processing 7450 samples.\nFinished processing 7500 samples.\nFinished processing 7550 samples.\nFinished processing 7600 samples.\nFinished processing 7650 samples.\nFinished processing 7700 samples.\nFinished processing 7750 samples.\nFinished processing 7800 samples.\nFinished processing 7850 samples.\nFinished processing 7900 samples.\nFinished processing 7950 samples.\nFinished processing 8000 samples.\nFinished processing 8050 samples.\nFinished processing 8100 samples.\nFinished processing 8150 samples.\nFinished processing 8200 samples.\nFinished processing 8250 samples.\nFinished processing 8300 samples.\nFinished processing 8350 samples.\nFinished processing 8400 samples.\nFinished processing 8450 samples.\nFinished processing 8500 samples.\nFinished processing 8550 samples.\nFinished processing 8600 samples.\nFinished processing 8650 samples.\nFinished processing 8700 samples.\nFinished processing 8750 samples.\nFinished processing 8800 samples.\nFinished processing 8850 samples.\nFinished processing 8900 samples.\nFinished processing 8950 samples.\nFinished processing 9000 samples.\nFinished processing 9050 samples.\nFinished processing 9100 samples.\nFinished processing 9150 samples.\nFinished processing 9200 samples.\nFinished processing 9250 samples.\nFinished processing 9300 samples.\nFinished processing 9350 samples.\nFinished processing 9400 samples.\nFinished processing 9450 samples.\nFinished processing 9500 samples.\nFinished processing 9550 samples.\nFinished processing 9600 samples.\nFinished processing 9650 samples.\nFinished processing 9700 samples.\nFinished processing 9750 samples.\nFinished processing 9800 samples.\nFinished processing 9850 samples.\nFinished processing 9900 samples.\nFinished processing 9950 samples.\nFinished processing 10000 samples.\nFinished processing 10050 samples.\nFinished processing 10100 samples.\nFinished processing 10150 samples.\nFinished processing 10200 samples.\nFinished processing 10250 samples.\nFinished processing 10300 samples.\nFinished processing 10350 samples.\nFinished processing 10400 samples.\nFinished processing 10450 samples.\nFinished processing 10500 samples.\nFinished processing 10550 samples.\nFinished processing 10557 samples.\nProcessing completed for 10557 samples.\n","output_type":"stream"}],"execution_count":9}]}