{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T21:35:51.313472Z",
     "iopub.status.busy": "2024-12-05T21:35:51.312811Z",
     "iopub.status.idle": "2024-12-05T21:36:08.873111Z",
     "shell.execute_reply": "2024-12-05T21:36:08.872236Z",
     "shell.execute_reply.started": "2024-12-05T21:35:51.313431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T21:37:28.019935Z",
     "iopub.status.busy": "2024-12-05T21:37:28.019090Z",
     "iopub.status.idle": "2024-12-05T21:37:31.594118Z",
     "shell.execute_reply": "2024-12-05T21:37:31.593461Z",
     "shell.execute_reply.started": "2024-12-05T21:37:28.019900Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a855b3b3ef8471ca88bce9a30bac930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95da241a465248ba90b830e93c9c5ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67601d6efe942b796639f8632c7783d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d8a4c2bb8841d1a533724597eb42fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382670df57ab49b6a2ac2f1f1c396a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "embedding_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/nn-text-classfication/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['Discussion'] = df['Discussion'].fillna('No Text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def replace_dates(text):\n",
    "    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n",
    "    return re.sub(date_pattern, '[DATE]', text)\n",
    "\n",
    "df['Discussion'] = df['Discussion'].apply(replace_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "total_samples = len(df)  \n",
    "\n",
    "embedding_data = []\n",
    "\n",
    "start_idx = 8500\n",
    "\n",
    "for idx in range(start_idx, total_samples, batch_size):\n",
    "    end_idx = min(idx + batch_size, total_samples)\n",
    "    batch = df.iloc[idx:end_idx]\n",
    "\n",
    "    for index, row in batch.iterrows():\n",
    "        text = row['Discussion']\n",
    "\n",
    "        inputs = tokenizer(text, padding='max_length', truncation=True, return_tensors='pt', max_length=512)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = embedding_model(**inputs)\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        sentence_embedding = last_hidden_states.mean(dim=1).squeeze().tolist()\n",
    "\n",
    "        embedding_data.append({\n",
    "            'SampleID': row['SampleID'],\n",
    "            'Category': row['Category'],\n",
    "            'Sentence_Embedding': sentence_embedding\n",
    "        })\n",
    "\n",
    "    embedding_df = pd.DataFrame(embedding_data)\n",
    "\n",
    "    embedding_df.to_csv('/kaggle/working/second_batch_embeddings.csv', index=False)\n",
    "    \n",
    "    print(f\"Finished processing {end_idx} samples.\")\n",
    "\n",
    "print(f\"Processing completed for {total_samples} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_first = pd.read_csv('/kaggle/input/embeddings-1/kaggle_first_batch_embeddings.csv')  # First dataset\n",
    "df_second = pd.read_csv('/kaggle/input/second-embeddings/second_batch_embeddings.csv')  # Second dataset\n",
    "\n",
    "df_combined = pd.concat([df_first, df_second], ignore_index=True)\n",
    "\n",
    "# Save the combined dataset to a new CSV\n",
    "df_combined.to_csv('/kaggle/working/Final_BERT_Embeddings_NN.csv', index=False)\n",
    "\n",
    "print(\"Datasets have been successfully combined and saved to 'Final_BERT_Embeddings_NN.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T21:36:14.640128Z",
     "iopub.status.busy": "2024-12-05T21:36:14.639799Z",
     "iopub.status.idle": "2024-12-05T21:36:14.744437Z",
     "shell.execute_reply": "2024-12-05T21:36:14.743555Z",
     "shell.execute_reply.started": "2024-12-05T21:36:14.640102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/nn-text-classfication/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T21:36:18.499353Z",
     "iopub.status.busy": "2024-12-05T21:36:18.499022Z",
     "iopub.status.idle": "2024-12-05T21:36:18.515212Z",
     "shell.execute_reply": "2024-12-05T21:36:18.514497Z",
     "shell.execute_reply.started": "2024-12-05T21:36:18.499325Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>Discussion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Managing cash flow effectively is crucial for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Civic engagement plays a key role in a democra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Proper warm-ups and cool-downs are essential t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data security is a growing concern as more peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Investing in stocks can be risky, but with car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SampleID                                         Discussion\n",
       "0         1  Managing cash flow effectively is crucial for ...\n",
       "1         2  Civic engagement plays a key role in a democra...\n",
       "2         3  Proper warm-ups and cool-downs are essential t...\n",
       "3         4  Data security is a growing concern as more peo...\n",
       "4         5  Investing in stocks can be risky, but with car..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T21:36:20.772709Z",
     "iopub.status.busy": "2024-12-05T21:36:20.772140Z",
     "iopub.status.idle": "2024-12-05T21:36:20.778822Z",
     "shell.execute_reply": "2024-12-05T21:36:20.777969Z",
     "shell.execute_reply.started": "2024-12-05T21:36:20.772676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fill NaN\n",
    "df['Discussion'] = df['Discussion'].fillna('No Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T21:36:22.857942Z",
     "iopub.status.busy": "2024-12-05T21:36:22.857572Z",
     "iopub.status.idle": "2024-12-05T21:36:23.028134Z",
     "shell.execute_reply": "2024-12-05T21:36:23.027423Z",
     "shell.execute_reply.started": "2024-12-05T21:36:22.857913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def replace_dates(text):\n",
    "    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n",
    "    return re.sub(date_pattern, '[DATE]', text)\n",
    "\n",
    "df['Discussion'] = df['Discussion'].apply(replace_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T21:38:04.790962Z",
     "iopub.status.busy": "2024-12-05T21:38:04.790065Z",
     "iopub.status.idle": "2024-12-05T23:15:19.407629Z",
     "shell.execute_reply": "2024-12-05T23:15:19.406700Z",
     "shell.execute_reply.started": "2024-12-05T21:38:04.790928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 50 samples.\n",
      "Finished processing 100 samples.\n",
      "Finished processing 150 samples.\n",
      "Finished processing 200 samples.\n",
      "Finished processing 250 samples.\n",
      "Finished processing 300 samples.\n",
      "Finished processing 350 samples.\n",
      "Finished processing 400 samples.\n",
      "Finished processing 450 samples.\n",
      "Finished processing 500 samples.\n",
      "Finished processing 550 samples.\n",
      "Finished processing 600 samples.\n",
      "Finished processing 650 samples.\n",
      "Finished processing 700 samples.\n",
      "Finished processing 750 samples.\n",
      "Finished processing 800 samples.\n",
      "Finished processing 850 samples.\n",
      "Finished processing 900 samples.\n",
      "Finished processing 950 samples.\n",
      "Finished processing 1000 samples.\n",
      "Finished processing 1050 samples.\n",
      "Finished processing 1100 samples.\n",
      "Finished processing 1150 samples.\n",
      "Finished processing 1200 samples.\n",
      "Finished processing 1250 samples.\n",
      "Finished processing 1300 samples.\n",
      "Finished processing 1350 samples.\n",
      "Finished processing 1400 samples.\n",
      "Finished processing 1450 samples.\n",
      "Finished processing 1500 samples.\n",
      "Finished processing 1550 samples.\n",
      "Finished processing 1600 samples.\n",
      "Finished processing 1650 samples.\n",
      "Finished processing 1700 samples.\n",
      "Finished processing 1750 samples.\n",
      "Finished processing 1800 samples.\n",
      "Finished processing 1850 samples.\n",
      "Finished processing 1900 samples.\n",
      "Finished processing 1950 samples.\n",
      "Finished processing 2000 samples.\n",
      "Finished processing 2050 samples.\n",
      "Finished processing 2100 samples.\n",
      "Finished processing 2150 samples.\n",
      "Finished processing 2200 samples.\n",
      "Finished processing 2250 samples.\n",
      "Finished processing 2300 samples.\n",
      "Finished processing 2350 samples.\n",
      "Finished processing 2400 samples.\n",
      "Finished processing 2450 samples.\n",
      "Finished processing 2500 samples.\n",
      "Finished processing 2550 samples.\n",
      "Finished processing 2600 samples.\n",
      "Finished processing 2650 samples.\n",
      "Finished processing 2700 samples.\n",
      "Finished processing 2750 samples.\n",
      "Finished processing 2800 samples.\n",
      "Finished processing 2850 samples.\n",
      "Finished processing 2900 samples.\n",
      "Finished processing 2950 samples.\n",
      "Finished processing 3000 samples.\n",
      "Finished processing 3050 samples.\n",
      "Finished processing 3100 samples.\n",
      "Finished processing 3150 samples.\n",
      "Finished processing 3200 samples.\n",
      "Finished processing 3250 samples.\n",
      "Finished processing 3300 samples.\n",
      "Finished processing 3350 samples.\n",
      "Finished processing 3400 samples.\n",
      "Finished processing 3450 samples.\n",
      "Finished processing 3500 samples.\n",
      "Finished processing 3550 samples.\n",
      "Finished processing 3600 samples.\n",
      "Finished processing 3650 samples.\n",
      "Finished processing 3700 samples.\n",
      "Finished processing 3750 samples.\n",
      "Finished processing 3800 samples.\n",
      "Finished processing 3850 samples.\n",
      "Finished processing 3900 samples.\n",
      "Finished processing 3950 samples.\n",
      "Finished processing 4000 samples.\n",
      "Finished processing 4050 samples.\n",
      "Finished processing 4100 samples.\n",
      "Finished processing 4150 samples.\n",
      "Finished processing 4200 samples.\n",
      "Finished processing 4250 samples.\n",
      "Finished processing 4300 samples.\n",
      "Finished processing 4350 samples.\n",
      "Finished processing 4400 samples.\n",
      "Finished processing 4450 samples.\n",
      "Finished processing 4500 samples.\n",
      "Finished processing 4550 samples.\n",
      "Finished processing 4600 samples.\n",
      "Finished processing 4650 samples.\n",
      "Finished processing 4700 samples.\n",
      "Finished processing 4750 samples.\n",
      "Finished processing 4800 samples.\n",
      "Finished processing 4850 samples.\n",
      "Finished processing 4900 samples.\n",
      "Finished processing 4950 samples.\n",
      "Finished processing 5000 samples.\n",
      "Finished processing 5050 samples.\n",
      "Finished processing 5100 samples.\n",
      "Finished processing 5150 samples.\n",
      "Finished processing 5200 samples.\n",
      "Finished processing 5250 samples.\n",
      "Finished processing 5300 samples.\n",
      "Finished processing 5350 samples.\n",
      "Finished processing 5400 samples.\n",
      "Finished processing 5450 samples.\n",
      "Finished processing 5500 samples.\n",
      "Finished processing 5550 samples.\n",
      "Finished processing 5600 samples.\n",
      "Finished processing 5650 samples.\n",
      "Finished processing 5700 samples.\n",
      "Finished processing 5750 samples.\n",
      "Finished processing 5800 samples.\n",
      "Finished processing 5850 samples.\n",
      "Finished processing 5900 samples.\n",
      "Finished processing 5950 samples.\n",
      "Finished processing 6000 samples.\n",
      "Finished processing 6050 samples.\n",
      "Finished processing 6100 samples.\n",
      "Finished processing 6150 samples.\n",
      "Finished processing 6200 samples.\n",
      "Finished processing 6250 samples.\n",
      "Finished processing 6300 samples.\n",
      "Finished processing 6350 samples.\n",
      "Finished processing 6400 samples.\n",
      "Finished processing 6450 samples.\n",
      "Finished processing 6500 samples.\n",
      "Finished processing 6550 samples.\n",
      "Finished processing 6600 samples.\n",
      "Finished processing 6650 samples.\n",
      "Finished processing 6700 samples.\n",
      "Finished processing 6750 samples.\n",
      "Finished processing 6800 samples.\n",
      "Finished processing 6850 samples.\n",
      "Finished processing 6900 samples.\n",
      "Finished processing 6950 samples.\n",
      "Finished processing 7000 samples.\n",
      "Finished processing 7050 samples.\n",
      "Finished processing 7100 samples.\n",
      "Finished processing 7150 samples.\n",
      "Finished processing 7200 samples.\n",
      "Finished processing 7250 samples.\n",
      "Finished processing 7300 samples.\n",
      "Finished processing 7350 samples.\n",
      "Finished processing 7400 samples.\n",
      "Finished processing 7450 samples.\n",
      "Finished processing 7500 samples.\n",
      "Finished processing 7550 samples.\n",
      "Finished processing 7600 samples.\n",
      "Finished processing 7650 samples.\n",
      "Finished processing 7700 samples.\n",
      "Finished processing 7750 samples.\n",
      "Finished processing 7800 samples.\n",
      "Finished processing 7850 samples.\n",
      "Finished processing 7900 samples.\n",
      "Finished processing 7950 samples.\n",
      "Finished processing 8000 samples.\n",
      "Finished processing 8050 samples.\n",
      "Finished processing 8100 samples.\n",
      "Finished processing 8150 samples.\n",
      "Finished processing 8200 samples.\n",
      "Finished processing 8250 samples.\n",
      "Finished processing 8300 samples.\n",
      "Finished processing 8350 samples.\n",
      "Finished processing 8400 samples.\n",
      "Finished processing 8450 samples.\n",
      "Finished processing 8500 samples.\n",
      "Finished processing 8550 samples.\n",
      "Finished processing 8600 samples.\n",
      "Finished processing 8650 samples.\n",
      "Finished processing 8700 samples.\n",
      "Finished processing 8750 samples.\n",
      "Finished processing 8800 samples.\n",
      "Finished processing 8850 samples.\n",
      "Finished processing 8900 samples.\n",
      "Finished processing 8950 samples.\n",
      "Finished processing 9000 samples.\n",
      "Finished processing 9050 samples.\n",
      "Finished processing 9100 samples.\n",
      "Finished processing 9150 samples.\n",
      "Finished processing 9200 samples.\n",
      "Finished processing 9250 samples.\n",
      "Finished processing 9300 samples.\n",
      "Finished processing 9350 samples.\n",
      "Finished processing 9400 samples.\n",
      "Finished processing 9450 samples.\n",
      "Finished processing 9500 samples.\n",
      "Finished processing 9550 samples.\n",
      "Finished processing 9600 samples.\n",
      "Finished processing 9650 samples.\n",
      "Finished processing 9700 samples.\n",
      "Finished processing 9750 samples.\n",
      "Finished processing 9800 samples.\n",
      "Finished processing 9850 samples.\n",
      "Finished processing 9900 samples.\n",
      "Finished processing 9950 samples.\n",
      "Finished processing 10000 samples.\n",
      "Finished processing 10050 samples.\n",
      "Finished processing 10100 samples.\n",
      "Finished processing 10150 samples.\n",
      "Finished processing 10200 samples.\n",
      "Finished processing 10250 samples.\n",
      "Finished processing 10300 samples.\n",
      "Finished processing 10350 samples.\n",
      "Finished processing 10400 samples.\n",
      "Finished processing 10450 samples.\n",
      "Finished processing 10500 samples.\n",
      "Finished processing 10550 samples.\n",
      "Finished processing 10557 samples.\n",
      "Processing completed for 10557 samples.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "total_samples = len(df)  \n",
    "\n",
    "embedding_data = []\n",
    "\n",
    "start_idx = 0\n",
    "\n",
    "for idx in range(start_idx, total_samples, batch_size):\n",
    "    end_idx = min(idx + batch_size, total_samples)\n",
    "    batch = df.iloc[idx:end_idx]\n",
    "\n",
    "    for index, row in batch.iterrows():\n",
    "        text = row['Discussion']\n",
    "\n",
    "        inputs = tokenizer(text, padding='max_length', truncation=True, return_tensors='pt', max_length=512)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = embedding_model(**inputs)\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        sentence_embedding = last_hidden_states.mean(dim=1).squeeze().tolist()\n",
    "\n",
    "        embedding_data.append({\n",
    "            'SampleID': row['SampleID'],\n",
    "            'Sentence_Embedding': sentence_embedding\n",
    "        })\n",
    "\n",
    "    embedding_df = pd.DataFrame(embedding_data)\n",
    "\n",
    "    embedding_df.to_csv('/kaggle/working/second_batch_embeddings.csv', index=False)\n",
    "    \n",
    "    print(f\"Finished processing {end_idx} samples.\")\n",
    "\n",
    "print(f\"Processing completed for {total_samples} samples.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6221550,
     "sourceId": 10089847,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
