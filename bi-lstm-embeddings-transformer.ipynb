{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10089847,"sourceType":"datasetVersion","datasetId":6221550}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport torch\nimport pandas as pd\nfrom transformers import BertTokenizer, BertModel\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score\nimport ast\nimport torch.optim as optim\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:15:21.411507Z","iopub.execute_input":"2024-12-11T13:15:21.411925Z","iopub.status.idle":"2024-12-11T13:15:23.671309Z","shell.execute_reply.started":"2024-12-11T13:15:21.411887Z","shell.execute_reply":"2024-12-11T13:15:23.670364Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:15:06.735639Z","iopub.execute_input":"2024-12-11T13:15:06.736061Z","iopub.status.idle":"2024-12-11T13:15:18.651905Z","shell.execute_reply.started":"2024-12-11T13:15:06.736026Z","shell.execute_reply":"2024-12-11T13:15:18.650794Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.3.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Prepare Train Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/nn-text-classfication/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:04.368801Z","iopub.execute_input":"2024-12-11T13:31:04.369506Z","iopub.status.idle":"2024-12-11T13:31:04.475071Z","shell.execute_reply.started":"2024-12-11T13:31:04.369469Z","shell.execute_reply":"2024-12-11T13:31:04.473867Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"model_new = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:15:35.772408Z","iopub.execute_input":"2024-12-11T13:15:35.772786Z","iopub.status.idle":"2024-12-11T13:15:38.735046Z","shell.execute_reply.started":"2024-12-11T13:15:35.772754Z","shell.execute_reply":"2024-12-11T13:15:38.734151Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b996562892244b288046b2d1e9289528"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0760c4ab81264837a34992982f055a68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3f99c2e6c664e8a827b2d9ceb0ecea7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e58d27b69d4486390285a2c116e201b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e50f93ac8a5440cb9dce596146c2854"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"281094f6ecb04c3cb6654a7e95a9e64f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f70a48d093c945b69d8c106585319a18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea8a25da7eb4d0faacfeffa91370d6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"223817499fb5465a8201bd437f2cf2b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e13526b6a68a4415ad94ee1ba89005e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0993de42f0864439863eee73fb958dfd"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:06.889781Z","iopub.execute_input":"2024-12-11T13:31:06.890462Z","iopub.status.idle":"2024-12-11T13:31:06.901024Z","shell.execute_reply.started":"2024-12-11T13:31:06.890423Z","shell.execute_reply":"2024-12-11T13:31:06.899837Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"   SampleID                                         Discussion  Category\n0         1  Without sitting down and doing it manually, yo...    Sports\n1         2               All your Search ends with this link.      STEM\n2         3  No, the program you're using is made to be com...      STEM\n3         4  Mike Woicik\\n\\nThe correct answer is: Mike Woi...    Sports\n4         5  No, but not because of why you might think. Wh...  Politics","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Discussion</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Without sitting down and doing it manually, yo...</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>All your Search ends with this link.</td>\n      <td>STEM</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>No, the program you're using is made to be com...</td>\n      <td>STEM</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Mike Woicik\\n\\nThe correct answer is: Mike Woi...</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>No, but not because of why you might think. Wh...</td>\n      <td>Politics</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"df_train['Discussion'] = df_train['Discussion'].fillna('No Text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:08.712878Z","iopub.execute_input":"2024-12-11T13:31:08.713303Z","iopub.status.idle":"2024-12-11T13:31:08.724222Z","shell.execute_reply.started":"2024-12-11T13:31:08.713271Z","shell.execute_reply":"2024-12-11T13:31:08.723326Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf_train['Discussion'] = df_train['Discussion'].apply(replace_dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:10.461631Z","iopub.execute_input":"2024-12-11T13:31:10.462002Z","iopub.status.idle":"2024-12-11T13:31:10.901253Z","shell.execute_reply.started":"2024-12-11T13:31:10.461950Z","shell.execute_reply":"2024-12-11T13:31:10.900455Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Generate embeddings for the dataset\nembeddings_train = model_new.encode(df_train['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n\n# Save embeddings to a file\nnp.save('news_embeddings_train.npy', embeddings_train)\n\n# Save corresponding labels\ndf_train['Category'].to_csv('news_labels.csv', index=False)\n\nprint(\"Embeddings and labels saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:14.814323Z","iopub.execute_input":"2024-12-11T13:31:14.814703Z","iopub.status.idle":"2024-12-11T13:31:27.357688Z","shell.execute_reply.started":"2024-12-11T13:31:14.814662Z","shell.execute_reply":"2024-12-11T13:31:27.356755Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/781 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f01aad74c142d88efdd22973e2fe16"}},"metadata":{}},{"name":"stdout","text":"Embeddings and labels saved successfully!\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"label_mapping = {\n    'Politics': 0,\n    'Sports': 1,\n    'Media': 2,\n    'Market & Economy': 3,\n    'STEM': 4\n}\ndf_train['Category']=df_train['Category'].map(label_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:30.121044Z","iopub.execute_input":"2024-12-11T13:31:30.121441Z","iopub.status.idle":"2024-12-11T13:31:30.129677Z","shell.execute_reply.started":"2024-12-11T13:31:30.121408Z","shell.execute_reply":"2024-12-11T13:31:30.128715Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"df_train['Category']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:32.479886Z","iopub.execute_input":"2024-12-11T13:31:32.480342Z","iopub.status.idle":"2024-12-11T13:31:32.488470Z","shell.execute_reply.started":"2024-12-11T13:31:32.480305Z","shell.execute_reply":"2024-12-11T13:31:32.487371Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"0        1\n1        4\n2        4\n3        1\n4        0\n        ..\n24984    1\n24985    3\n24986    3\n24987    0\n24988    2\nName: Category, Length: 24989, dtype: int64"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"labels = list(df_train['Category'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:34.578718Z","iopub.execute_input":"2024-12-11T13:31:34.579218Z","iopub.status.idle":"2024-12-11T13:31:34.585832Z","shell.execute_reply.started":"2024-12-11T13:31:34.579177Z","shell.execute_reply":"2024-12-11T13:31:34.584849Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, sentences, labels):\n        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32) for x in sentences])  \n        self.labels = torch.tensor(labels, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        return self.sentences[idx], self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:36.499414Z","iopub.execute_input":"2024-12-11T13:31:36.499805Z","iopub.status.idle":"2024-12-11T13:31:36.506094Z","shell.execute_reply.started":"2024-12-11T13:31:36.499771Z","shell.execute_reply":"2024-12-11T13:31:36.505031Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(embeddings_train, labels, test_size=0.2, random_state=42)\n\ntrain_dataset = TextDataset(X_train, y_train)\nval_dataset = TextDataset(X_val, y_val)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:38.256623Z","iopub.execute_input":"2024-12-11T13:31:38.257041Z","iopub.status.idle":"2024-12-11T13:31:38.574161Z","shell.execute_reply.started":"2024-12-11T13:31:38.257004Z","shell.execute_reply":"2024-12-11T13:31:38.573051Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"for batch in train_dataloader:\n    sentences, labels = batch\n    print(f\"Train batch size: {sentences.size(0)}\")\n    print(f\"Sentence shape: {sentences.shape}\")\n    print(f\"Labels shape: {labels.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:31:40.258571Z","iopub.execute_input":"2024-12-11T13:31:40.258962Z","iopub.status.idle":"2024-12-11T13:31:40.267962Z","shell.execute_reply.started":"2024-12-11T13:31:40.258926Z","shell.execute_reply":"2024-12-11T13:31:40.266874Z"}},"outputs":[{"name":"stdout","text":"Train batch size: 32\nSentence shape: torch.Size([32, 384])\nLabels shape: torch.Size([32])\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"# Archi BI LSTM","metadata":{}},{"cell_type":"code","source":"class BiLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.5):\n        super(BiLSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # BiLSTM Layer\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n                            batch_first=True, bidirectional=True, dropout=dropout)\n        \n        # Dropout and BatchNorm\n        self.dropout = nn.Dropout(dropout)\n        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)\n        \n        # Fully Connected Layer\n        self.fc = nn.Linear(hidden_size * 2, num_classes)\n\n    def forward(self, x):\n        device = x.device\n        x = x.unsqueeze(1)\n\n        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device) \n        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n\n        out, _ = self.lstm(x, (h0, c0))  \n        \n        last_hidden = out[:, -1, :]  \n        last_hidden = self.batch_norm(last_hidden)\n        last_hidden = self.dropout(last_hidden)\n\n        # Fully connected layer\n        output = self.fc(last_hidden)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:18:24.888295Z","iopub.execute_input":"2024-12-11T13:18:24.888693Z","iopub.status.idle":"2024-12-11T13:18:24.898488Z","shell.execute_reply.started":"2024-12-11T13:18:24.888662Z","shell.execute_reply":"2024-12-11T13:18:24.897357Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def train_model(model, train_dataloader, optimizer, criterion, scheduler, \n                epochs=5, save_path='model.pth'):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        all_preds = []\n        all_labels = []\n\n        for sentences, labels in train_dataloader:\n            sentences = sentences.float().to(device)\n            labels = labels.long().to(device)\n\n            optimizer.zero_grad()\n            outputs = model(sentences)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # Gradient clipping\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, preds = torch.max(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n        epoch_loss = running_loss / len(train_dataloader)\n        epoch_acc = accuracy_score(all_labels, all_preds) * 100\n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n\n        scheduler.step()\n\n    print(\"Training complete.\")\n    # Save the entire model\n    torch.save(model, save_path)\n\n    print(f\"Model saved to {save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:19:18.227463Z","iopub.execute_input":"2024-12-11T13:19:18.228661Z","iopub.status.idle":"2024-12-11T13:19:18.237275Z","shell.execute_reply.started":"2024-12-11T13:19:18.228607Z","shell.execute_reply":"2024-12-11T13:19:18.236240Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def val_model(model, val_dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for sentences, labels in val_dataloader:\n            sentences = sentences.float().to(device) \n            labels = labels.long().to(device)\n            outputs = model(sentences)\n            _, preds = torch.max(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:19:22.400723Z","iopub.execute_input":"2024-12-11T13:19:22.401181Z","iopub.status.idle":"2024-12-11T13:19:22.407897Z","shell.execute_reply.started":"2024-12-11T13:19:22.401145Z","shell.execute_reply":"2024-12-11T13:19:22.406671Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Hyperparameters\ninput_size = 384\nhidden_size = 128\nnum_layers = 1\nnum_classes = len(df_train['Category'])\nlearning_rate = 0.001\ndropout = 0.5\nweight_decay = 1e-4\nepochs = 20\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Model, criterion, optimizer, and scheduler\nmodel = BiLSTM(input_size, hidden_size, num_layers, num_classes, dropout=dropout).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:19:32.500789Z","iopub.execute_input":"2024-12-11T13:19:32.501748Z","iopub.status.idle":"2024-12-11T13:19:32.631005Z","shell.execute_reply.started":"2024-12-11T13:19:32.501710Z","shell.execute_reply":"2024-12-11T13:19:32.629959Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"train_model(model, train_dataloader, optimizer, criterion,scheduler, 50, save_path='bilstm_model_entire.pth')\nval_model(model, val_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:19:46.116263Z","iopub.execute_input":"2024-12-11T13:19:46.116631Z","iopub.status.idle":"2024-12-11T13:22:31.619489Z","shell.execute_reply.started":"2024-12-11T13:19:46.116600Z","shell.execute_reply":"2024-12-11T13:22:31.618442Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/50], Loss: 2.6532, Accuracy: 69.74%\nEpoch [2/50], Loss: 0.8988, Accuracy: 73.59%\nEpoch [3/50], Loss: 0.7533, Accuracy: 74.05%\nEpoch [4/50], Loss: 0.7373, Accuracy: 74.05%\nEpoch [5/50], Loss: 0.7304, Accuracy: 74.41%\nEpoch [6/50], Loss: 0.7026, Accuracy: 75.11%\nEpoch [7/50], Loss: 0.7017, Accuracy: 75.52%\nEpoch [8/50], Loss: 0.6961, Accuracy: 75.41%\nEpoch [9/50], Loss: 0.6944, Accuracy: 75.52%\nEpoch [10/50], Loss: 0.6963, Accuracy: 75.38%\nEpoch [11/50], Loss: 0.6906, Accuracy: 75.69%\nEpoch [12/50], Loss: 0.6927, Accuracy: 75.61%\nEpoch [13/50], Loss: 0.6890, Accuracy: 75.78%\nEpoch [14/50], Loss: 0.6929, Accuracy: 75.69%\nEpoch [15/50], Loss: 0.6870, Accuracy: 75.97%\nEpoch [16/50], Loss: 0.6887, Accuracy: 75.78%\nEpoch [17/50], Loss: 0.6898, Accuracy: 75.60%\nEpoch [18/50], Loss: 0.6876, Accuracy: 75.81%\nEpoch [19/50], Loss: 0.6867, Accuracy: 75.81%\nEpoch [20/50], Loss: 0.6846, Accuracy: 75.71%\nEpoch [21/50], Loss: 0.6877, Accuracy: 75.64%\nEpoch [22/50], Loss: 0.6881, Accuracy: 75.72%\nEpoch [23/50], Loss: 0.6877, Accuracy: 75.70%\nEpoch [24/50], Loss: 0.6900, Accuracy: 75.56%\nEpoch [25/50], Loss: 0.6823, Accuracy: 75.73%\nEpoch [26/50], Loss: 0.6895, Accuracy: 75.68%\nEpoch [27/50], Loss: 0.6899, Accuracy: 75.65%\nEpoch [28/50], Loss: 0.6874, Accuracy: 75.66%\nEpoch [29/50], Loss: 0.6885, Accuracy: 75.76%\nEpoch [30/50], Loss: 0.6887, Accuracy: 75.66%\nEpoch [31/50], Loss: 0.6865, Accuracy: 75.86%\nEpoch [32/50], Loss: 0.6848, Accuracy: 75.90%\nEpoch [33/50], Loss: 0.6903, Accuracy: 75.37%\nEpoch [34/50], Loss: 0.6869, Accuracy: 75.93%\nEpoch [35/50], Loss: 0.6877, Accuracy: 75.87%\nEpoch [36/50], Loss: 0.6896, Accuracy: 75.55%\nEpoch [37/50], Loss: 0.6881, Accuracy: 75.67%\nEpoch [38/50], Loss: 0.6890, Accuracy: 75.58%\nEpoch [39/50], Loss: 0.6884, Accuracy: 75.61%\nEpoch [40/50], Loss: 0.6834, Accuracy: 75.88%\nEpoch [41/50], Loss: 0.6872, Accuracy: 75.90%\nEpoch [42/50], Loss: 0.6879, Accuracy: 75.88%\nEpoch [43/50], Loss: 0.6868, Accuracy: 75.75%\nEpoch [44/50], Loss: 0.6867, Accuracy: 75.93%\nEpoch [45/50], Loss: 0.6861, Accuracy: 75.91%\nEpoch [46/50], Loss: 0.6840, Accuracy: 75.80%\nEpoch [47/50], Loss: 0.6908, Accuracy: 75.63%\nEpoch [48/50], Loss: 0.6836, Accuracy: 75.69%\nEpoch [49/50], Loss: 0.6862, Accuracy: 75.73%\nEpoch [50/50], Loss: 0.6868, Accuracy: 75.72%\nTraining complete.\nModel saved to bilstm_model_entire.pth\nValidation Accuracy: 76.11%\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0.7611044417767107"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"df_test=pd.read_csv('/kaggle/input/nn-text-classfication/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:22:36.477601Z","iopub.execute_input":"2024-12-11T13:22:36.477990Z","iopub.status.idle":"2024-12-11T13:22:36.606788Z","shell.execute_reply.started":"2024-12-11T13:22:36.477944Z","shell.execute_reply":"2024-12-11T13:22:36.605586Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"df_test['Discussion'] = df_test['Discussion'].fillna('No Text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:22:38.183341Z","iopub.execute_input":"2024-12-11T13:22:38.183720Z","iopub.status.idle":"2024-12-11T13:22:38.191613Z","shell.execute_reply.started":"2024-12-11T13:22:38.183689Z","shell.execute_reply":"2024-12-11T13:22:38.190355Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf_test['Discussion'] = df_test['Discussion'].apply(replace_dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:22:40.225403Z","iopub.execute_input":"2024-12-11T13:22:40.225771Z","iopub.status.idle":"2024-12-11T13:22:40.419238Z","shell.execute_reply.started":"2024-12-11T13:22:40.225738Z","shell.execute_reply":"2024-12-11T13:22:40.418335Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Generate embeddings for the dataset\nembeddings_test = model_new.encode(df_test['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n\n# Save embeddings to a file\nnp.save('news_embeddings_train.npy', embeddings_test)\n\nprint(\"Embeddings and labels saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:22:42.526349Z","iopub.execute_input":"2024-12-11T13:22:42.526715Z","iopub.status.idle":"2024-12-11T13:22:47.922268Z","shell.execute_reply.started":"2024-12-11T13:22:42.526684Z","shell.execute_reply":"2024-12-11T13:22:47.921289Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/330 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a407c6976acc40c6975dd20df221f072"}},"metadata":{}},{"name":"stdout","text":"Embeddings and labels saved successfully!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, sentences, sample_ids):\n        # Store sentences as a tensor\n        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32) for x in sentences])   # Converting string to list using eval\n        self.sample_ids = sample_ids\n\n    def __len__(self):\n        return len(self.sentences)  # Use self.sentences here\n\n    def __getitem__(self, idx):\n        # Return sentence embeddings and the corresponding sample ID\n        return self.sentences[idx], self.sample_ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:22:50.518164Z","iopub.execute_input":"2024-12-11T13:22:50.518559Z","iopub.status.idle":"2024-12-11T13:22:50.525164Z","shell.execute_reply.started":"2024-12-11T13:22:50.518526Z","shell.execute_reply":"2024-12-11T13:22:50.523927Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"test_dataset = CustomDataset(embeddings_test, df_test['SampleID'])\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:22:52.870141Z","iopub.execute_input":"2024-12-11T13:22:52.870871Z","iopub.status.idle":"2024-12-11T13:22:52.999474Z","shell.execute_reply.started":"2024-12-11T13:22:52.870837Z","shell.execute_reply":"2024-12-11T13:22:52.998615Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"save_csv_path = '/kaggle/working/predictions_BILSTM1.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:22:54.781895Z","iopub.execute_input":"2024-12-11T13:22:54.782405Z","iopub.status.idle":"2024-12-11T13:22:54.788135Z","shell.execute_reply.started":"2024-12-11T13:22:54.782358Z","shell.execute_reply":"2024-12-11T13:22:54.786888Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def test_model(model, val_dataloader, save_csv_path='predictions.csv', device='cuda'):\n    model.eval()  # Set model to evaluation mode\n    all_preds = []\n    sample_ids = []  # To store sample IDs\n\n    with torch.no_grad():\n        for sentences, ids in val_dataloader:  # Extract sentences and IDs from DataLoader\n            sentences = sentences.float().to(device)  # Move sentences to GPU (or CPU if needed)\n            outputs = model(sentences)\n            _, preds = torch.max(outputs, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())  # Move predictions back to CPU\n            sample_ids.extend(ids.numpy())  # Collect the sample IDs\n\n    # Save predictions to a CSV file\n    predictions_df = pd.DataFrame({\n        'SampleID': sample_ids,\n        'Category': all_preds\n    })\n    predictions_df.to_csv(save_csv_path, index=False)\n    print(f\"Predictions saved to {save_csv_path}\")\n    \n    return predictions_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:22:56.935484Z","iopub.execute_input":"2024-12-11T13:22:56.936215Z","iopub.status.idle":"2024-12-11T13:22:56.942406Z","shell.execute_reply.started":"2024-12-11T13:22:56.936179Z","shell.execute_reply":"2024-12-11T13:22:56.941406Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"test_model(model, test_dataloader, save_csv_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:23:08.578195Z","iopub.execute_input":"2024-12-11T13:23:08.578605Z","iopub.status.idle":"2024-12-11T13:23:09.027168Z","shell.execute_reply.started":"2024-12-11T13:23:08.578570Z","shell.execute_reply":"2024-12-11T13:23:09.026144Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to /kaggle/working/predictions_BILSTM1.csv\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"       SampleID  Category\n0             1         3\n1             2         0\n2             3         1\n3             4         4\n4             5         3\n...         ...       ...\n10552     10553         4\n10553     10554         3\n10554     10555         3\n10555     10556         0\n10556     10557         2\n\n[10557 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10552</th>\n      <td>10553</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10553</th>\n      <td>10554</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10554</th>\n      <td>10555</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10555</th>\n      <td>10556</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10556</th>\n      <td>10557</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>10557 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":34}]}