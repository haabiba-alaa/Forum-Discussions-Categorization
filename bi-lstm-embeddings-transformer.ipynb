{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10089847,"sourceType":"datasetVersion","datasetId":6221550}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:06:13.586143Z","iopub.execute_input":"2024-12-15T17:06:13.586904Z","iopub.status.idle":"2024-12-15T17:06:23.485679Z","shell.execute_reply.started":"2024-12-15T17:06:13.586864Z","shell.execute_reply":"2024-12-15T17:06:23.484537Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nimport torch\nimport pandas as pd\nfrom transformers import BertTokenizer, BertModel\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score\nimport ast\nimport torch.optim as optim\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:06:39.989032Z","iopub.execute_input":"2024-12-15T17:06:39.989941Z","iopub.status.idle":"2024-12-15T17:06:59.167510Z","shell.execute_reply.started":"2024-12-15T17:06:39.989903Z","shell.execute_reply":"2024-12-15T17:06:59.166624Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:06:59.168832Z","iopub.execute_input":"2024-12-15T17:06:59.169376Z","iopub.status.idle":"2024-12-15T17:06:59.224336Z","shell.execute_reply.started":"2024-12-15T17:06:59.169347Z","shell.execute_reply":"2024-12-15T17:06:59.223368Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Prepare Train Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/nn-text-classfication/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:06:59.445766Z","iopub.execute_input":"2024-12-15T17:06:59.446340Z","iopub.status.idle":"2024-12-15T17:06:59.558502Z","shell.execute_reply.started":"2024-12-15T17:06:59.446299Z","shell.execute_reply":"2024-12-15T17:06:59.557234Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model_new = SentenceTransformer('all-mpnet-base-v2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:07:05.835981Z","iopub.execute_input":"2024-12-15T17:07:05.836326Z","iopub.status.idle":"2024-12-15T17:07:17.148172Z","shell.execute_reply.started":"2024-12-15T17:07:05.836296Z","shell.execute_reply":"2024-12-15T17:07:17.147368Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3ba9bfa332f4e1a8d6f8e69932382af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b7ef569be754e97a98d75137181fe9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f0da568108d431bbffb949c6069c42d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fdcefc28d8242488e89e224aa50085b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3448ae4c739a4d09b6deae7240874510"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0379e67a973e4732be0a16a919d7a1b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4184faf5eb5462ba99b465621020f3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5950d9cf22a94eab9bfcdadeb1fc6307"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55674a8cae1e471ca19af718e91e90c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b9a924d1a844b9cb30735c7adb9a67c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28bfcd8bba7e41c3b68c57efb291f8e6"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:07:19.859734Z","iopub.execute_input":"2024-12-15T17:07:19.860062Z","iopub.status.idle":"2024-12-15T17:07:19.876372Z","shell.execute_reply.started":"2024-12-15T17:07:19.860035Z","shell.execute_reply":"2024-12-15T17:07:19.875615Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   SampleID                                         Discussion  Category\n0         1  Without sitting down and doing it manually, yo...    Sports\n1         2               All your Search ends with this link.      STEM\n2         3  No, the program you're using is made to be com...      STEM\n3         4  Mike Woicik\\n\\nThe correct answer is: Mike Woi...    Sports\n4         5  No, but not because of why you might think. Wh...  Politics","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Discussion</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Without sitting down and doing it manually, yo...</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>All your Search ends with this link.</td>\n      <td>STEM</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>No, the program you're using is made to be com...</td>\n      <td>STEM</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Mike Woicik\\n\\nThe correct answer is: Mike Woi...</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>No, but not because of why you might think. Wh...</td>\n      <td>Politics</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df_train['Discussion'] = df_train['Discussion'].fillna('No Text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:07:21.857206Z","iopub.execute_input":"2024-12-15T17:07:21.857926Z","iopub.status.idle":"2024-12-15T17:07:21.868440Z","shell.execute_reply.started":"2024-12-15T17:07:21.857890Z","shell.execute_reply":"2024-12-15T17:07:21.867428Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf_train['Discussion'] = df_train['Discussion'].apply(replace_dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:07:23.341781Z","iopub.execute_input":"2024-12-15T17:07:23.342614Z","iopub.status.idle":"2024-12-15T17:07:23.739952Z","shell.execute_reply.started":"2024-12-15T17:07:23.342582Z","shell.execute_reply":"2024-12-15T17:07:23.739157Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Generate embeddings for the dataset\nembeddings_train = model_new.encode(df_train['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n\n# Save embeddings to a file\nnp.save('news_embeddings_train.npy', embeddings_train)\n\n# Save corresponding labels\ndf_train['Category'].to_csv('news_labels.csv', index=False)\n\nprint(\"Embeddings and labels saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:07:24.547597Z","iopub.execute_input":"2024-12-15T17:07:24.548477Z","iopub.status.idle":"2024-12-15T17:08:44.480541Z","shell.execute_reply.started":"2024-12-15T17:07:24.548446Z","shell.execute_reply":"2024-12-15T17:08:44.479629Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/781 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8dfa780b5ff452dafe1684e74f2cdda"}},"metadata":{}},{"name":"stdout","text":"Embeddings and labels saved successfully!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Example of checking the value counts\ncategory_distribution = df_train['Category'].value_counts()\nprint(category_distribution)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T22:51:11.320307Z","iopub.execute_input":"2024-12-14T22:51:11.320943Z","iopub.status.idle":"2024-12-14T22:51:11.332143Z","shell.execute_reply.started":"2024-12-14T22:51:11.320908Z","shell.execute_reply":"2024-12-14T22:51:11.331363Z"}},"outputs":[{"name":"stdout","text":"Category\nSTEM                5530\nMarket & Economy    5530\nSports              5529\nPolitics            4200\nMedia               4200\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"class_counts = [5530, 5530, 5529, 4200, 4200]\nclass_names = ['STEM', 'Market & Economy', 'Sports', 'Politics', 'Media']\nnum_classes = len(class_counts)\n\n# Compute class weights\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.arange(num_classes), y=np.repeat(np.arange(num_classes), class_counts))\nclass_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n\nprint(\"Class weights:\", class_weights_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T23:05:51.782107Z","iopub.execute_input":"2024-12-14T23:05:51.782435Z","iopub.status.idle":"2024-12-14T23:05:51.902989Z","shell.execute_reply.started":"2024-12-14T23:05:51.782408Z","shell.execute_reply":"2024-12-14T23:05:51.901488Z"}},"outputs":[{"name":"stdout","text":"Class weights: tensor([0.9038, 0.9038, 0.9039, 1.1900, 1.1900], device='cuda:0')\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"label_mapping = {\n    'Politics': 0,\n    'Sports': 1,\n    'Media': 2,\n    'Market & Economy': 3,\n    'STEM': 4\n}\ndf_train['Category']=df_train['Category'].map(label_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:08:47.659488Z","iopub.execute_input":"2024-12-15T17:08:47.660179Z","iopub.status.idle":"2024-12-15T17:08:47.668924Z","shell.execute_reply.started":"2024-12-15T17:08:47.660144Z","shell.execute_reply":"2024-12-15T17:08:47.668063Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df_train['Category']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:08:49.063715Z","iopub.execute_input":"2024-12-15T17:08:49.064064Z","iopub.status.idle":"2024-12-15T17:08:49.072330Z","shell.execute_reply.started":"2024-12-15T17:08:49.064034Z","shell.execute_reply":"2024-12-15T17:08:49.071442Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0        1\n1        4\n2        4\n3        1\n4        0\n        ..\n24984    1\n24985    3\n24986    3\n24987    0\n24988    2\nName: Category, Length: 24989, dtype: int64"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"labels = list(df_train['Category'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:08:51.040344Z","iopub.execute_input":"2024-12-15T17:08:51.041196Z","iopub.status.idle":"2024-12-15T17:08:51.047185Z","shell.execute_reply.started":"2024-12-15T17:08:51.041146Z","shell.execute_reply":"2024-12-15T17:08:51.046398Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, sentences, labels):\n        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32) for x in sentences])  \n        self.labels = torch.tensor(labels, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        return self.sentences[idx], self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:08:52.112793Z","iopub.execute_input":"2024-12-15T17:08:52.113127Z","iopub.status.idle":"2024-12-15T17:08:52.118394Z","shell.execute_reply.started":"2024-12-15T17:08:52.113098Z","shell.execute_reply":"2024-12-15T17:08:52.117476Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(embeddings_train, labels, test_size=0.2, random_state=42)\n\ntrain_dataset = TextDataset(X_train, y_train)\nval_dataset = TextDataset(X_val, y_val)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:08:54.858161Z","iopub.execute_input":"2024-12-15T17:08:54.858950Z","iopub.status.idle":"2024-12-15T17:08:55.236400Z","shell.execute_reply.started":"2024-12-15T17:08:54.858915Z","shell.execute_reply":"2024-12-15T17:08:55.235705Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"for batch in train_dataloader:\n    sentences, labels = batch\n    print(f\"Train batch size: {sentences.size(0)}\")\n    print(f\"Sentence shape: {sentences.shape}\")\n    print(f\"Labels shape: {labels.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:08:56.295306Z","iopub.execute_input":"2024-12-15T17:08:56.295673Z","iopub.status.idle":"2024-12-15T17:08:56.305363Z","shell.execute_reply.started":"2024-12-15T17:08:56.295627Z","shell.execute_reply":"2024-12-15T17:08:56.304426Z"}},"outputs":[{"name":"stdout","text":"Train batch size: 32\nSentence shape: torch.Size([32, 768])\nLabels shape: torch.Size([32])\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Archi BI LSTM","metadata":{}},{"cell_type":"code","source":"class BiLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.5):\n        super(BiLSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # BiLSTM Layer\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n                            batch_first=True, bidirectional=True, dropout=dropout)\n        \n        # Dropout and BatchNorm\n        self.dropout = nn.Dropout(dropout)\n        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)\n        \n        # Fully Connected Layer\n        self.fc = nn.Linear(hidden_size * 2, num_classes)\n\n    def forward(self, x):\n        device = x.device\n        x = x.unsqueeze(1)\n\n        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device) \n        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n\n        out, _ = self.lstm(x, (h0, c0))  \n        \n        last_hidden = out[:, -1, :]  \n        last_hidden = self.batch_norm(last_hidden)\n        last_hidden = self.dropout(last_hidden)\n\n        # Fully connected layer\n        output = self.fc(last_hidden)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:09:03.430229Z","iopub.execute_input":"2024-12-15T17:09:03.430893Z","iopub.status.idle":"2024-12-15T17:09:03.438171Z","shell.execute_reply.started":"2024-12-15T17:09:03.430855Z","shell.execute_reply":"2024-12-15T17:09:03.437214Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train_model(model, train_dataloader, optimizer, criterion, scheduler, \n                epochs=5, save_path='model.pth'):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        all_preds = []\n        all_labels = []\n\n        for sentences, labels in train_dataloader:\n            sentences = sentences.float().to(device)\n            labels = labels.long().to(device)\n\n            optimizer.zero_grad()\n            outputs = model(sentences)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # Gradient clipping\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, preds = torch.max(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n        epoch_loss = running_loss / len(train_dataloader)\n        epoch_acc = accuracy_score(all_labels, all_preds) * 100\n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n\n        scheduler.step()\n\n    print(\"Training complete.\")\n    # Save the entire model\n    torch.save(model, save_path)\n\n    print(f\"Model saved to {save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:09:05.767938Z","iopub.execute_input":"2024-12-15T17:09:05.768284Z","iopub.status.idle":"2024-12-15T17:09:05.775485Z","shell.execute_reply.started":"2024-12-15T17:09:05.768253Z","shell.execute_reply":"2024-12-15T17:09:05.774478Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def val_model(model, val_dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for sentences, labels in val_dataloader:\n            sentences = sentences.float().to(device) \n            labels = labels.long().to(device)\n            outputs = model(sentences)\n            _, preds = torch.max(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:09:08.395036Z","iopub.execute_input":"2024-12-15T17:09:08.395374Z","iopub.status.idle":"2024-12-15T17:09:08.401154Z","shell.execute_reply.started":"2024-12-15T17:09:08.395346Z","shell.execute_reply":"2024-12-15T17:09:08.400225Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Hyperparameters\ninput_size = 768\nhidden_size = 128\nnum_layers = 2\nnum_classes = 5\nlearning_rate = 0.001\ndropout = 0.5\nweight_decay = 1e-4\nepochs = 20\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Model, criterion, optimizer, and scheduler\nmodel = BiLSTM(input_size, hidden_size, num_layers, num_classes, dropout=dropout).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:09:22.326160Z","iopub.execute_input":"2024-12-15T17:09:22.327018Z","iopub.status.idle":"2024-12-15T17:09:22.348028Z","shell.execute_reply.started":"2024-12-15T17:09:22.326985Z","shell.execute_reply":"2024-12-15T17:09:22.347324Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"train_model(model, train_dataloader, optimizer, criterion,scheduler, 50, save_path='bilstm_model_entire.pth')\nval_model(model, val_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:09:25.800885Z","iopub.execute_input":"2024-12-15T17:09:25.801627Z","iopub.status.idle":"2024-12-15T17:11:50.961706Z","shell.execute_reply.started":"2024-12-15T17:09:25.801594Z","shell.execute_reply":"2024-12-15T17:11:50.960848Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/50], Loss: 0.8003, Accuracy: 72.02%\nEpoch [2/50], Loss: 0.6998, Accuracy: 76.13%\nEpoch [3/50], Loss: 0.6827, Accuracy: 76.53%\nEpoch [4/50], Loss: 0.6690, Accuracy: 77.04%\nEpoch [5/50], Loss: 0.6635, Accuracy: 76.95%\nEpoch [6/50], Loss: 0.6309, Accuracy: 78.10%\nEpoch [7/50], Loss: 0.6234, Accuracy: 78.21%\nEpoch [8/50], Loss: 0.6201, Accuracy: 78.35%\nEpoch [9/50], Loss: 0.6210, Accuracy: 78.38%\nEpoch [10/50], Loss: 0.6185, Accuracy: 78.46%\nEpoch [11/50], Loss: 0.6094, Accuracy: 78.72%\nEpoch [12/50], Loss: 0.6080, Accuracy: 78.60%\nEpoch [13/50], Loss: 0.6080, Accuracy: 78.66%\nEpoch [14/50], Loss: 0.6082, Accuracy: 78.66%\nEpoch [15/50], Loss: 0.6104, Accuracy: 78.71%\nEpoch [16/50], Loss: 0.6099, Accuracy: 78.84%\nEpoch [17/50], Loss: 0.6071, Accuracy: 78.75%\nEpoch [18/50], Loss: 0.6065, Accuracy: 78.71%\nEpoch [19/50], Loss: 0.6086, Accuracy: 78.68%\nEpoch [20/50], Loss: 0.6043, Accuracy: 78.80%\nEpoch [21/50], Loss: 0.6085, Accuracy: 78.77%\nEpoch [22/50], Loss: 0.6102, Accuracy: 78.63%\nEpoch [23/50], Loss: 0.6075, Accuracy: 78.64%\nEpoch [24/50], Loss: 0.6090, Accuracy: 78.74%\nEpoch [25/50], Loss: 0.6099, Accuracy: 79.11%\nEpoch [26/50], Loss: 0.6035, Accuracy: 78.85%\nEpoch [27/50], Loss: 0.6081, Accuracy: 78.80%\nEpoch [28/50], Loss: 0.6096, Accuracy: 78.74%\nEpoch [29/50], Loss: 0.6084, Accuracy: 78.72%\nEpoch [30/50], Loss: 0.6055, Accuracy: 78.91%\nEpoch [31/50], Loss: 0.6098, Accuracy: 78.88%\nEpoch [32/50], Loss: 0.6088, Accuracy: 78.82%\nEpoch [33/50], Loss: 0.6070, Accuracy: 78.91%\nEpoch [34/50], Loss: 0.6060, Accuracy: 78.89%\nEpoch [35/50], Loss: 0.6069, Accuracy: 78.53%\nEpoch [36/50], Loss: 0.6076, Accuracy: 78.59%\nEpoch [37/50], Loss: 0.6084, Accuracy: 78.75%\nEpoch [38/50], Loss: 0.6100, Accuracy: 78.55%\nEpoch [39/50], Loss: 0.6068, Accuracy: 78.78%\nEpoch [40/50], Loss: 0.6073, Accuracy: 78.75%\nEpoch [41/50], Loss: 0.6082, Accuracy: 78.45%\nEpoch [42/50], Loss: 0.6083, Accuracy: 78.85%\nEpoch [43/50], Loss: 0.6046, Accuracy: 78.64%\nEpoch [44/50], Loss: 0.6091, Accuracy: 78.88%\nEpoch [45/50], Loss: 0.6077, Accuracy: 78.95%\nEpoch [46/50], Loss: 0.6044, Accuracy: 78.91%\nEpoch [47/50], Loss: 0.6033, Accuracy: 78.93%\nEpoch [48/50], Loss: 0.6040, Accuracy: 78.86%\nEpoch [49/50], Loss: 0.6073, Accuracy: 78.90%\nEpoch [50/50], Loss: 0.6087, Accuracy: 78.68%\nTraining complete.\nModel saved to bilstm_model_entire.pth\nValidation Accuracy: 78.57%\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0.7857142857142857"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"df_test=pd.read_csv('/kaggle/input/nn-text-classfication/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:11:54.899915Z","iopub.execute_input":"2024-12-15T17:11:54.900496Z","iopub.status.idle":"2024-12-15T17:11:54.983261Z","shell.execute_reply.started":"2024-12-15T17:11:54.900461Z","shell.execute_reply":"2024-12-15T17:11:54.982539Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"df_test['Discussion'] = df_test['Discussion'].fillna('No Text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:11:56.545841Z","iopub.execute_input":"2024-12-15T17:11:56.546755Z","iopub.status.idle":"2024-12-15T17:11:56.553061Z","shell.execute_reply.started":"2024-12-15T17:11:56.546707Z","shell.execute_reply":"2024-12-15T17:11:56.552164Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf_test['Discussion'] = df_test['Discussion'].apply(replace_dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:11:58.450326Z","iopub.execute_input":"2024-12-15T17:11:58.451183Z","iopub.status.idle":"2024-12-15T17:11:58.621762Z","shell.execute_reply.started":"2024-12-15T17:11:58.451132Z","shell.execute_reply":"2024-12-15T17:11:58.620808Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Generate embeddings for the dataset\nembeddings_test = model_new.encode(df_test['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n\n# Save embeddings to a file\nnp.save('news_embeddings_train.npy', embeddings_test)\n\nprint(\"Embeddings and labels saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:12:00.463762Z","iopub.execute_input":"2024-12-15T17:12:00.464331Z","iopub.status.idle":"2024-12-15T17:12:34.570139Z","shell.execute_reply.started":"2024-12-15T17:12:00.464296Z","shell.execute_reply":"2024-12-15T17:12:34.569227Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/330 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f465f2d71ee44a2b9372e54bdf3a2cf"}},"metadata":{}},{"name":"stdout","text":"Embeddings and labels saved successfully!\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, sentences, sample_ids):\n        # Store sentences as a tensor\n        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32) for x in sentences])   # Converting string to list using eval\n        self.sample_ids = sample_ids\n\n    def __len__(self):\n        return len(self.sentences)  # Use self.sentences here\n\n    def __getitem__(self, idx):\n        # Return sentence embeddings and the corresponding sample ID\n        return self.sentences[idx], self.sample_ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:12:36.397067Z","iopub.execute_input":"2024-12-15T17:12:36.397746Z","iopub.status.idle":"2024-12-15T17:12:36.402862Z","shell.execute_reply.started":"2024-12-15T17:12:36.397710Z","shell.execute_reply":"2024-12-15T17:12:36.401969Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"test_dataset = CustomDataset(embeddings_test, df_test['SampleID'])\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:12:38.642547Z","iopub.execute_input":"2024-12-15T17:12:38.642908Z","iopub.status.idle":"2024-12-15T17:12:38.768412Z","shell.execute_reply.started":"2024-12-15T17:12:38.642876Z","shell.execute_reply":"2024-12-15T17:12:38.767715Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"save_csv_path = '/kaggle/working/predictions_BILSTM.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:12:43.295448Z","iopub.execute_input":"2024-12-15T17:12:43.295817Z","iopub.status.idle":"2024-12-15T17:12:43.299962Z","shell.execute_reply.started":"2024-12-15T17:12:43.295785Z","shell.execute_reply":"2024-12-15T17:12:43.298971Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def test_model(model, val_dataloader, save_csv_path='predictions.csv'):\n    model.eval()  # Set model to evaluation mode\n    all_preds = []\n    sample_ids = []  # To store sample IDs\n\n    with torch.no_grad():\n        for sentences, ids in val_dataloader:  # Extract sentences and IDs from DataLoader\n            sentences = sentences.float().to(device)  # Move sentences to GPU (or CPU if needed)\n            outputs = model(sentences)\n            _, preds = torch.max(outputs, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())  # Move predictions back to CPU\n            sample_ids.extend(ids.numpy())  # Collect the sample IDs\n\n    # Save predictions to a CSV file\n    predictions_df = pd.DataFrame({\n        'SampleID': sample_ids,\n        'Category': all_preds\n    })\n    predictions_df.to_csv(save_csv_path, index=False)\n    print(f\"Predictions saved to {save_csv_path}\")\n    \n    return predictions_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:12:45.282090Z","iopub.execute_input":"2024-12-15T17:12:45.282791Z","iopub.status.idle":"2024-12-15T17:12:45.288413Z","shell.execute_reply.started":"2024-12-15T17:12:45.282755Z","shell.execute_reply":"2024-12-15T17:12:45.287549Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"test_model(model, test_dataloader, save_csv_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:13:19.861346Z","iopub.execute_input":"2024-12-15T17:13:19.861723Z","iopub.status.idle":"2024-12-15T17:13:20.307072Z","shell.execute_reply.started":"2024-12-15T17:13:19.861690Z","shell.execute_reply":"2024-12-15T17:13:20.306198Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to /kaggle/working/predictions_BILSTM.csv\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"       SampleID  Category\n0             1         3\n1             2         0\n2             3         1\n3             4         4\n4             5         3\n...         ...       ...\n10552     10553         4\n10553     10554         3\n10554     10555         3\n10555     10556         0\n10556     10557         2\n\n[10557 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10552</th>\n      <td>10553</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10553</th>\n      <td>10554</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10554</th>\n      <td>10555</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10555</th>\n      <td>10556</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10556</th>\n      <td>10557</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>10557 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":32}]}