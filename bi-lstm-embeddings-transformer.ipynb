{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:15:21.411925Z",
     "iopub.status.busy": "2024-12-11T13:15:21.411507Z",
     "iopub.status.idle": "2024-12-11T13:15:23.671309Z",
     "shell.execute_reply": "2024-12-11T13:15:23.670364Z",
     "shell.execute_reply.started": "2024-12-11T13:15:21.411887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import ast\n",
    "import torch.optim as optim\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:15:06.736061Z",
     "iopub.status.busy": "2024-12-11T13:15:06.735639Z",
     "iopub.status.idle": "2024-12-11T13:15:18.651905Z",
     "shell.execute_reply": "2024-12-11T13:15:18.650794Z",
     "shell.execute_reply.started": "2024-12-11T13:15:06.736026Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:04.369506Z",
     "iopub.status.busy": "2024-12-11T13:31:04.368801Z",
     "iopub.status.idle": "2024-12-11T13:31:04.475071Z",
     "shell.execute_reply": "2024-12-11T13:31:04.473867Z",
     "shell.execute_reply.started": "2024-12-11T13:31:04.369469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/nn-text-classfication/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:15:35.772786Z",
     "iopub.status.busy": "2024-12-11T13:15:35.772408Z",
     "iopub.status.idle": "2024-12-11T13:15:38.735046Z",
     "shell.execute_reply": "2024-12-11T13:15:38.734151Z",
     "shell.execute_reply.started": "2024-12-11T13:15:35.772754Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b996562892244b288046b2d1e9289528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0760c4ab81264837a34992982f055a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f99c2e6c664e8a827b2d9ceb0ecea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e58d27b69d4486390285a2c116e201b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e50f93ac8a5440cb9dce596146c2854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281094f6ecb04c3cb6654a7e95a9e64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70a48d093c945b69d8c106585319a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea8a25da7eb4d0faacfeffa91370d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223817499fb5465a8201bd437f2cf2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13526b6a68a4415ad94ee1ba89005e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0993de42f0864439863eee73fb958dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_new = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:06.890462Z",
     "iopub.status.busy": "2024-12-11T13:31:06.889781Z",
     "iopub.status.idle": "2024-12-11T13:31:06.901024Z",
     "shell.execute_reply": "2024-12-11T13:31:06.899837Z",
     "shell.execute_reply.started": "2024-12-11T13:31:06.890423Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Without sitting down and doing it manually, yo...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>All your Search ends with this link.</td>\n",
       "      <td>STEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No, the program you're using is made to be com...</td>\n",
       "      <td>STEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mike Woicik\\n\\nThe correct answer is: Mike Woi...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No, but not because of why you might think. Wh...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SampleID                                         Discussion  Category\n",
       "0         1  Without sitting down and doing it manually, yo...    Sports\n",
       "1         2               All your Search ends with this link.      STEM\n",
       "2         3  No, the program you're using is made to be com...      STEM\n",
       "3         4  Mike Woicik\\n\\nThe correct answer is: Mike Woi...    Sports\n",
       "4         5  No, but not because of why you might think. Wh...  Politics"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:08.713303Z",
     "iopub.status.busy": "2024-12-11T13:31:08.712878Z",
     "iopub.status.idle": "2024-12-11T13:31:08.724222Z",
     "shell.execute_reply": "2024-12-11T13:31:08.723326Z",
     "shell.execute_reply.started": "2024-12-11T13:31:08.713271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['Discussion'] = df_train['Discussion'].fillna('No Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:10.462002Z",
     "iopub.status.busy": "2024-12-11T13:31:10.461631Z",
     "iopub.status.idle": "2024-12-11T13:31:10.901253Z",
     "shell.execute_reply": "2024-12-11T13:31:10.900455Z",
     "shell.execute_reply.started": "2024-12-11T13:31:10.461950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def replace_dates(text):\n",
    "    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n",
    "    return re.sub(date_pattern, '[DATE]', text)\n",
    "\n",
    "df_train['Discussion'] = df_train['Discussion'].apply(replace_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:14.814703Z",
     "iopub.status.busy": "2024-12-11T13:31:14.814323Z",
     "iopub.status.idle": "2024-12-11T13:31:27.357688Z",
     "shell.execute_reply": "2024-12-11T13:31:27.356755Z",
     "shell.execute_reply.started": "2024-12-11T13:31:14.814662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f01aad74c142d88efdd22973e2fe16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings and labels saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the dataset\n",
    "embeddings_train = model_new.encode(df_train['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n",
    "\n",
    "# Save embeddings to a file\n",
    "np.save('news_embeddings_train.npy', embeddings_train)\n",
    "\n",
    "# Save corresponding labels\n",
    "df_train['Category'].to_csv('news_labels.csv', index=False)\n",
    "\n",
    "print(\"Embeddings and labels saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:30.121441Z",
     "iopub.status.busy": "2024-12-11T13:31:30.121044Z",
     "iopub.status.idle": "2024-12-11T13:31:30.129677Z",
     "shell.execute_reply": "2024-12-11T13:31:30.128715Z",
     "shell.execute_reply.started": "2024-12-11T13:31:30.121408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'Politics': 0,\n",
    "    'Sports': 1,\n",
    "    'Media': 2,\n",
    "    'Market & Economy': 3,\n",
    "    'STEM': 4\n",
    "}\n",
    "df_train['Category']=df_train['Category'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:32.480342Z",
     "iopub.status.busy": "2024-12-11T13:31:32.479886Z",
     "iopub.status.idle": "2024-12-11T13:31:32.488470Z",
     "shell.execute_reply": "2024-12-11T13:31:32.487371Z",
     "shell.execute_reply.started": "2024-12-11T13:31:32.480305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        4\n",
       "2        4\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "24984    1\n",
       "24985    3\n",
       "24986    3\n",
       "24987    0\n",
       "24988    2\n",
       "Name: Category, Length: 24989, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:34.579218Z",
     "iopub.status.busy": "2024-12-11T13:31:34.578718Z",
     "iopub.status.idle": "2024-12-11T13:31:34.585832Z",
     "shell.execute_reply": "2024-12-11T13:31:34.584849Z",
     "shell.execute_reply.started": "2024-12-11T13:31:34.579177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels = list(df_train['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:36.499805Z",
     "iopub.status.busy": "2024-12-11T13:31:36.499414Z",
     "iopub.status.idle": "2024-12-11T13:31:36.506094Z",
     "shell.execute_reply": "2024-12-11T13:31:36.505031Z",
     "shell.execute_reply.started": "2024-12-11T13:31:36.499771Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sentences, labels):\n",
    "        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32) for x in sentences])  \n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:38.257041Z",
     "iopub.status.busy": "2024-12-11T13:31:38.256623Z",
     "iopub.status.idle": "2024-12-11T13:31:38.574161Z",
     "shell.execute_reply": "2024-12-11T13:31:38.573051Z",
     "shell.execute_reply.started": "2024-12-11T13:31:38.257004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(embeddings_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "val_dataset = TextDataset(X_val, y_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:31:40.258962Z",
     "iopub.status.busy": "2024-12-11T13:31:40.258571Z",
     "iopub.status.idle": "2024-12-11T13:31:40.267962Z",
     "shell.execute_reply": "2024-12-11T13:31:40.266874Z",
     "shell.execute_reply.started": "2024-12-11T13:31:40.258926Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch size: 32\n",
      "Sentence shape: torch.Size([32, 384])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    sentences, labels = batch\n",
    "    print(f\"Train batch size: {sentences.size(0)}\")\n",
    "    print(f\"Sentence shape: {sentences.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archi BI LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:18:24.888693Z",
     "iopub.status.busy": "2024-12-11T13:18:24.888295Z",
     "iopub.status.idle": "2024-12-11T13:18:24.898488Z",
     "shell.execute_reply": "2024-12-11T13:18:24.897357Z",
     "shell.execute_reply.started": "2024-12-11T13:18:24.888662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.5):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # BiLSTM Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # Dropout and BatchNorm\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "        \n",
    "        last_hidden = out[:, -1, :]  \n",
    "        last_hidden = self.batch_norm(last_hidden)\n",
    "        last_hidden = self.dropout(last_hidden)\n",
    "\n",
    "        # Fully connected layer\n",
    "        output = self.fc(last_hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:19:18.228661Z",
     "iopub.status.busy": "2024-12-11T13:19:18.227463Z",
     "iopub.status.idle": "2024-12-11T13:19:18.237275Z",
     "shell.execute_reply": "2024-12-11T13:19:18.236240Z",
     "shell.execute_reply.started": "2024-12-11T13:19:18.228607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, optimizer, criterion, scheduler, \n",
    "                epochs=5, save_path='model.pth'):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for sentences, labels in train_dataloader:\n",
    "            sentences = sentences.float().to(device)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sentences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds) * 100\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    # Save the entire model\n",
    "    torch.save(model, save_path)\n",
    "\n",
    "    print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:19:22.401181Z",
     "iopub.status.busy": "2024-12-11T13:19:22.400723Z",
     "iopub.status.idle": "2024-12-11T13:19:22.407897Z",
     "shell.execute_reply": "2024-12-11T13:19:22.406671Z",
     "shell.execute_reply.started": "2024-12-11T13:19:22.401145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def val_model(model, val_dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentences, labels in val_dataloader:\n",
    "            sentences = sentences.float().to(device) \n",
    "            labels = labels.long().to(device)\n",
    "            outputs = model(sentences)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:19:32.501748Z",
     "iopub.status.busy": "2024-12-11T13:19:32.500789Z",
     "iopub.status.idle": "2024-12-11T13:19:32.631005Z",
     "shell.execute_reply": "2024-12-11T13:19:32.629959Z",
     "shell.execute_reply.started": "2024-12-11T13:19:32.501710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 384\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "num_classes = 5\n",
    "learning_rate = 0.001\n",
    "dropout = 0.5\n",
    "weight_decay = 1e-4\n",
    "epochs = 20\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Model, criterion, optimizer, and scheduler\n",
    "model = BiLSTM(input_size, hidden_size, num_layers, num_classes, dropout=dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:19:46.116631Z",
     "iopub.status.busy": "2024-12-11T13:19:46.116263Z",
     "iopub.status.idle": "2024-12-11T13:22:31.619489Z",
     "shell.execute_reply": "2024-12-11T13:22:31.618442Z",
     "shell.execute_reply.started": "2024-12-11T13:19:46.116600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.6532, Accuracy: 69.74%\n",
      "Epoch [2/50], Loss: 0.8988, Accuracy: 73.59%\n",
      "Epoch [3/50], Loss: 0.7533, Accuracy: 74.05%\n",
      "Epoch [4/50], Loss: 0.7373, Accuracy: 74.05%\n",
      "Epoch [5/50], Loss: 0.7304, Accuracy: 74.41%\n",
      "Epoch [6/50], Loss: 0.7026, Accuracy: 75.11%\n",
      "Epoch [7/50], Loss: 0.7017, Accuracy: 75.52%\n",
      "Epoch [8/50], Loss: 0.6961, Accuracy: 75.41%\n",
      "Epoch [9/50], Loss: 0.6944, Accuracy: 75.52%\n",
      "Epoch [10/50], Loss: 0.6963, Accuracy: 75.38%\n",
      "Epoch [11/50], Loss: 0.6906, Accuracy: 75.69%\n",
      "Epoch [12/50], Loss: 0.6927, Accuracy: 75.61%\n",
      "Epoch [13/50], Loss: 0.6890, Accuracy: 75.78%\n",
      "Epoch [14/50], Loss: 0.6929, Accuracy: 75.69%\n",
      "Epoch [15/50], Loss: 0.6870, Accuracy: 75.97%\n",
      "Epoch [16/50], Loss: 0.6887, Accuracy: 75.78%\n",
      "Epoch [17/50], Loss: 0.6898, Accuracy: 75.60%\n",
      "Epoch [18/50], Loss: 0.6876, Accuracy: 75.81%\n",
      "Epoch [19/50], Loss: 0.6867, Accuracy: 75.81%\n",
      "Epoch [20/50], Loss: 0.6846, Accuracy: 75.71%\n",
      "Epoch [21/50], Loss: 0.6877, Accuracy: 75.64%\n",
      "Epoch [22/50], Loss: 0.6881, Accuracy: 75.72%\n",
      "Epoch [23/50], Loss: 0.6877, Accuracy: 75.70%\n",
      "Epoch [24/50], Loss: 0.6900, Accuracy: 75.56%\n",
      "Epoch [25/50], Loss: 0.6823, Accuracy: 75.73%\n",
      "Epoch [26/50], Loss: 0.6895, Accuracy: 75.68%\n",
      "Epoch [27/50], Loss: 0.6899, Accuracy: 75.65%\n",
      "Epoch [28/50], Loss: 0.6874, Accuracy: 75.66%\n",
      "Epoch [29/50], Loss: 0.6885, Accuracy: 75.76%\n",
      "Epoch [30/50], Loss: 0.6887, Accuracy: 75.66%\n",
      "Epoch [31/50], Loss: 0.6865, Accuracy: 75.86%\n",
      "Epoch [32/50], Loss: 0.6848, Accuracy: 75.90%\n",
      "Epoch [33/50], Loss: 0.6903, Accuracy: 75.37%\n",
      "Epoch [34/50], Loss: 0.6869, Accuracy: 75.93%\n",
      "Epoch [35/50], Loss: 0.6877, Accuracy: 75.87%\n",
      "Epoch [36/50], Loss: 0.6896, Accuracy: 75.55%\n",
      "Epoch [37/50], Loss: 0.6881, Accuracy: 75.67%\n",
      "Epoch [38/50], Loss: 0.6890, Accuracy: 75.58%\n",
      "Epoch [39/50], Loss: 0.6884, Accuracy: 75.61%\n",
      "Epoch [40/50], Loss: 0.6834, Accuracy: 75.88%\n",
      "Epoch [41/50], Loss: 0.6872, Accuracy: 75.90%\n",
      "Epoch [42/50], Loss: 0.6879, Accuracy: 75.88%\n",
      "Epoch [43/50], Loss: 0.6868, Accuracy: 75.75%\n",
      "Epoch [44/50], Loss: 0.6867, Accuracy: 75.93%\n",
      "Epoch [45/50], Loss: 0.6861, Accuracy: 75.91%\n",
      "Epoch [46/50], Loss: 0.6840, Accuracy: 75.80%\n",
      "Epoch [47/50], Loss: 0.6908, Accuracy: 75.63%\n",
      "Epoch [48/50], Loss: 0.6836, Accuracy: 75.69%\n",
      "Epoch [49/50], Loss: 0.6862, Accuracy: 75.73%\n",
      "Epoch [50/50], Loss: 0.6868, Accuracy: 75.72%\n",
      "Training complete.\n",
      "Model saved to bilstm_model_entire.pth\n",
      "Validation Accuracy: 76.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7611044417767107"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, train_dataloader, optimizer, criterion,scheduler, 50, save_path='bilstm_model_entire.pth')\n",
    "val_model(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:22:36.477990Z",
     "iopub.status.busy": "2024-12-11T13:22:36.477601Z",
     "iopub.status.idle": "2024-12-11T13:22:36.606788Z",
     "shell.execute_reply": "2024-12-11T13:22:36.605586Z",
     "shell.execute_reply.started": "2024-12-11T13:22:36.477944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('/kaggle/input/nn-text-classfication/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:22:38.183720Z",
     "iopub.status.busy": "2024-12-11T13:22:38.183341Z",
     "iopub.status.idle": "2024-12-11T13:22:38.191613Z",
     "shell.execute_reply": "2024-12-11T13:22:38.190355Z",
     "shell.execute_reply.started": "2024-12-11T13:22:38.183689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test['Discussion'] = df_test['Discussion'].fillna('No Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:22:40.225771Z",
     "iopub.status.busy": "2024-12-11T13:22:40.225403Z",
     "iopub.status.idle": "2024-12-11T13:22:40.419238Z",
     "shell.execute_reply": "2024-12-11T13:22:40.418335Z",
     "shell.execute_reply.started": "2024-12-11T13:22:40.225738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def replace_dates(text):\n",
    "    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n",
    "    return re.sub(date_pattern, '[DATE]', text)\n",
    "\n",
    "df_test['Discussion'] = df_test['Discussion'].apply(replace_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:22:42.526715Z",
     "iopub.status.busy": "2024-12-11T13:22:42.526349Z",
     "iopub.status.idle": "2024-12-11T13:22:47.922268Z",
     "shell.execute_reply": "2024-12-11T13:22:47.921289Z",
     "shell.execute_reply.started": "2024-12-11T13:22:42.526684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a407c6976acc40c6975dd20df221f072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings and labels saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the dataset\n",
    "embeddings_test = model_new.encode(df_test['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n",
    "\n",
    "# Save embeddings to a file\n",
    "np.save('news_embeddings_train.npy', embeddings_test)\n",
    "\n",
    "print(\"Embeddings and labels saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:22:50.518559Z",
     "iopub.status.busy": "2024-12-11T13:22:50.518164Z",
     "iopub.status.idle": "2024-12-11T13:22:50.525164Z",
     "shell.execute_reply": "2024-12-11T13:22:50.523927Z",
     "shell.execute_reply.started": "2024-12-11T13:22:50.518526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sentences, sample_ids):\n",
    "        # Store sentences as a tensor\n",
    "        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32) for x in sentences])   # Converting string to list using eval\n",
    "        self.sample_ids = sample_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)  # Use self.sentences here\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return sentence embeddings and the corresponding sample ID\n",
    "        return self.sentences[idx], self.sample_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:22:52.870871Z",
     "iopub.status.busy": "2024-12-11T13:22:52.870141Z",
     "iopub.status.idle": "2024-12-11T13:22:52.999474Z",
     "shell.execute_reply": "2024-12-11T13:22:52.998615Z",
     "shell.execute_reply.started": "2024-12-11T13:22:52.870837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(embeddings_test, df_test['SampleID'])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:22:54.782405Z",
     "iopub.status.busy": "2024-12-11T13:22:54.781895Z",
     "iopub.status.idle": "2024-12-11T13:22:54.788135Z",
     "shell.execute_reply": "2024-12-11T13:22:54.786888Z",
     "shell.execute_reply.started": "2024-12-11T13:22:54.782358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_csv_path = '/kaggle/working/predictions_BILSTM1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:22:56.936215Z",
     "iopub.status.busy": "2024-12-11T13:22:56.935484Z",
     "iopub.status.idle": "2024-12-11T13:22:56.942406Z",
     "shell.execute_reply": "2024-12-11T13:22:56.941406Z",
     "shell.execute_reply.started": "2024-12-11T13:22:56.936179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, val_dataloader, save_csv_path='predictions.csv', device='cuda'):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    sample_ids = []  # To store sample IDs\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentences, ids in val_dataloader:  # Extract sentences and IDs from DataLoader\n",
    "            sentences = sentences.float().to(device)  # Move sentences to GPU (or CPU if needed)\n",
    "            outputs = model(sentences)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())  # Move predictions back to CPU\n",
    "            sample_ids.extend(ids.numpy())  # Collect the sample IDs\n",
    "\n",
    "    # Save predictions to a CSV file\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'SampleID': sample_ids,\n",
    "        'Category': all_preds\n",
    "    })\n",
    "    predictions_df.to_csv(save_csv_path, index=False)\n",
    "    print(f\"Predictions saved to {save_csv_path}\")\n",
    "    \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:23:08.578605Z",
     "iopub.status.busy": "2024-12-11T13:23:08.578195Z",
     "iopub.status.idle": "2024-12-11T13:23:09.027168Z",
     "shell.execute_reply": "2024-12-11T13:23:09.026144Z",
     "shell.execute_reply.started": "2024-12-11T13:23:08.578570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/predictions_BILSTM1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10552</th>\n",
       "      <td>10553</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10553</th>\n",
       "      <td>10554</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10554</th>\n",
       "      <td>10555</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10555</th>\n",
       "      <td>10556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10556</th>\n",
       "      <td>10557</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10557 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SampleID  Category\n",
       "0             1         3\n",
       "1             2         0\n",
       "2             3         1\n",
       "3             4         4\n",
       "4             5         3\n",
       "...         ...       ...\n",
       "10552     10553         4\n",
       "10553     10554         3\n",
       "10554     10555         3\n",
       "10555     10556         0\n",
       "10556     10557         2\n",
       "\n",
       "[10557 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_dataloader, save_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6221550,
     "sourceId": 10089847,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
