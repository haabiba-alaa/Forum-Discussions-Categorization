{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10089847,"sourceType":"datasetVersion","datasetId":6221550}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport torch\nimport pandas as pd\nfrom transformers import BertTokenizer, BertModel\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score\nimport ast\nimport torch.optim as optim\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:09:23.460769Z","iopub.execute_input":"2024-12-11T14:09:23.461459Z","iopub.status.idle":"2024-12-11T14:09:41.840373Z","shell.execute_reply.started":"2024-12-11T14:09:23.461422Z","shell.execute_reply":"2024-12-11T14:09:41.839726Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:09:08.371493Z","iopub.execute_input":"2024-12-11T14:09:08.371829Z","iopub.status.idle":"2024-12-11T14:09:18.044690Z","shell.execute_reply.started":"2024-12-11T14:09:08.371797Z","shell.execute_reply":"2024-12-11T14:09:18.043849Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.3.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/nn-text-classfication/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:09:45.854441Z","iopub.execute_input":"2024-12-11T14:09:45.855061Z","iopub.status.idle":"2024-12-11T14:09:46.037503Z","shell.execute_reply.started":"2024-12-11T14:09:45.855030Z","shell.execute_reply":"2024-12-11T14:09:46.036547Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model_new = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:09:47.341541Z","iopub.execute_input":"2024-12-11T14:09:47.341880Z","iopub.status.idle":"2024-12-11T14:09:50.368757Z","shell.execute_reply.started":"2024-12-11T14:09:47.341849Z","shell.execute_reply":"2024-12-11T14:09:50.368014Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"598470e8767b4113ace13f11c4edac64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"983d742e1786461c9753295bcb290005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61461028dca1413183c00b260b2f75b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82f0dc51f7ea463883712d3af30cfe03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19f5eb65f29d454f815041d5c5692239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da34123fc5e4474880fc51466aa18495"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"420a77944bdb40089d1d2d898bbc6039"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb01618b2e6543c88a6f5f99aef67505"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26626e0e46fc497f8c888076c7983194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acc61ec690c04771a4c3fbe744652b6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53c8c7a7d5d747a1b143fc1c801a770c"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:09:53.001414Z","iopub.execute_input":"2024-12-11T14:09:53.002324Z","iopub.status.idle":"2024-12-11T14:09:53.016035Z","shell.execute_reply.started":"2024-12-11T14:09:53.002270Z","shell.execute_reply":"2024-12-11T14:09:53.015171Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   SampleID                                         Discussion  Category\n0         1  Without sitting down and doing it manually, yo...    Sports\n1         2               All your Search ends with this link.      STEM\n2         3  No, the program you're using is made to be com...      STEM\n3         4  Mike Woicik\\n\\nThe correct answer is: Mike Woi...    Sports\n4         5  No, but not because of why you might think. Wh...  Politics","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Discussion</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Without sitting down and doing it manually, yo...</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>All your Search ends with this link.</td>\n      <td>STEM</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>No, the program you're using is made to be com...</td>\n      <td>STEM</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Mike Woicik\\n\\nThe correct answer is: Mike Woi...</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>No, but not because of why you might think. Wh...</td>\n      <td>Politics</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df_train['Discussion'] = df_train['Discussion'].fillna('No Text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:09:54.962866Z","iopub.execute_input":"2024-12-11T14:09:54.963538Z","iopub.status.idle":"2024-12-11T14:09:54.975070Z","shell.execute_reply.started":"2024-12-11T14:09:54.963501Z","shell.execute_reply":"2024-12-11T14:09:54.974366Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf_train['Discussion'] = df_train['Discussion'].apply(replace_dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:09:56.602057Z","iopub.execute_input":"2024-12-11T14:09:56.602436Z","iopub.status.idle":"2024-12-11T14:09:56.992972Z","shell.execute_reply.started":"2024-12-11T14:09:56.602404Z","shell.execute_reply":"2024-12-11T14:09:56.992339Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Generate embeddings for the dataset\nembeddings_train = model_new.encode(df_train['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n\n# Save embeddings to a file\nnp.save('news_embeddings_train.npy', embeddings_train)\n\n# Save corresponding labels\ndf_train['Category'].to_csv('news_labels.csv', index=False)\n\nprint(\"Embeddings and labels saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:09:59.246030Z","iopub.execute_input":"2024-12-11T14:09:59.246955Z","iopub.status.idle":"2024-12-11T14:10:11.965645Z","shell.execute_reply.started":"2024-12-11T14:09:59.246904Z","shell.execute_reply":"2024-12-11T14:10:11.964793Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/781 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb25f4604a19429ab78be1fa40f0a7ed"}},"metadata":{}},{"name":"stdout","text":"Embeddings and labels saved successfully!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"label_mapping = {\n    'Politics': 0,\n    'Sports': 1,\n    'Media': 2,\n    'Market & Economy': 3,\n    'STEM': 4\n}\ndf_train['Category']=df_train['Category'].map(label_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:14.508011Z","iopub.execute_input":"2024-12-11T14:10:14.508710Z","iopub.status.idle":"2024-12-11T14:10:14.517883Z","shell.execute_reply.started":"2024-12-11T14:10:14.508673Z","shell.execute_reply":"2024-12-11T14:10:14.517068Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df_train['Category']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:16.363938Z","iopub.execute_input":"2024-12-11T14:10:16.364754Z","iopub.status.idle":"2024-12-11T14:10:16.372011Z","shell.execute_reply.started":"2024-12-11T14:10:16.364715Z","shell.execute_reply":"2024-12-11T14:10:16.371022Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0        1\n1        4\n2        4\n3        1\n4        0\n        ..\n24984    1\n24985    3\n24986    3\n24987    0\n24988    2\nName: Category, Length: 24989, dtype: int64"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"labels = list(df_train['Category'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:18.210079Z","iopub.execute_input":"2024-12-11T14:10:18.210442Z","iopub.status.idle":"2024-12-11T14:10:18.216339Z","shell.execute_reply.started":"2024-12-11T14:10:18.210409Z","shell.execute_reply":"2024-12-11T14:10:18.215420Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, sentences, labels):\n        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32).unsqueeze(0) for x in sentences])\n        self.labels = torch.tensor(labels, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        return self.sentences[idx], self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:20.258503Z","iopub.execute_input":"2024-12-11T14:10:20.259265Z","iopub.status.idle":"2024-12-11T14:10:20.264310Z","shell.execute_reply.started":"2024-12-11T14:10:20.259232Z","shell.execute_reply":"2024-12-11T14:10:20.263374Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(embeddings_train, labels, test_size=0.2, random_state=42)\n\ntrain_dataset = TextDataset(X_train, y_train)\nval_dataset = TextDataset(X_val, y_val)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:22.158719Z","iopub.execute_input":"2024-12-11T14:10:22.159056Z","iopub.status.idle":"2024-12-11T14:10:22.550311Z","shell.execute_reply.started":"2024-12-11T14:10:22.159026Z","shell.execute_reply":"2024-12-11T14:10:22.549349Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for batch in train_dataloader:\n    sentences, labels = batch\n    print(f\"Train batch size: {sentences.size(0)}\")\n    print(f\"Sentence shape: {sentences.shape}\")\n    print(f\"Labels shape: {labels.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:24.604734Z","iopub.execute_input":"2024-12-11T14:10:24.605080Z","iopub.status.idle":"2024-12-11T14:10:24.614821Z","shell.execute_reply.started":"2024-12-11T14:10:24.605049Z","shell.execute_reply":"2024-12-11T14:10:24.614035Z"}},"outputs":[{"name":"stdout","text":"Train batch size: 32\nSentence shape: torch.Size([32, 1, 384])\nLabels shape: torch.Size([32])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"class TextCNN(nn.Module):\n    def __init__(self, input_size, num_classes, kernel_sizes, num_filters, dropout=0.5):\n        super(TextCNN, self).__init__()\n        self.convs = nn.ModuleList([\n            nn.Conv2d(1, num_filters, (k, input_size)) for k in kernel_sizes if k <= 1\n        ])\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(len(kernel_sizes) * num_filters, num_classes)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # [32, 1, 768]\n        \n        conv_outputs = [torch.relu(conv(x)).squeeze(3) for conv in self.convs]  # Conv + ReLU\n        pooled_outputs = [torch.max(output, dim=2)[0] for output in conv_outputs]  # Max Pooling\n        out = torch.cat(pooled_outputs, dim=1) \n        out = self.dropout(out)\n        out = self.fc(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:27.595392Z","iopub.execute_input":"2024-12-11T14:10:27.596374Z","iopub.status.idle":"2024-12-11T14:10:27.604778Z","shell.execute_reply.started":"2024-12-11T14:10:27.596314Z","shell.execute_reply":"2024-12-11T14:10:27.603858Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Training function\ndef train_model(model, train_dataloader, optimizer, criterion, epochs=5, save_path='model.pth', scheduler=None):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        all_preds = []\n        all_labels = []\n        \n        for sentences, labels in train_dataloader:\n            sentences = sentences.float().to(device)\n            labels = labels.long().to(device)\n\n            optimizer.zero_grad()\n            outputs = model(sentences)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # Gradient clipping\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, preds = torch.max(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n         \n        if scheduler:\n            scheduler.step()\n        \n        epoch_loss = running_loss / len(train_dataloader)\n        epoch_acc = accuracy_score(all_labels, all_preds) * 100\n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n\n    print(\"Training complete.\")\n    torch.save(model.state_dict(), save_path)\n    print(f\"Model saved to {save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:29.405367Z","iopub.execute_input":"2024-12-11T14:10:29.405721Z","iopub.status.idle":"2024-12-11T14:10:29.413243Z","shell.execute_reply.started":"2024-12-11T14:10:29.405692Z","shell.execute_reply":"2024-12-11T14:10:29.412409Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Validation function\ndef val_model(model, val_dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for sentences, labels in val_dataloader:\n            sentences = sentences.float().to(device)\n            labels = labels.long().to(device)\n            outputs = model(sentences)\n            _, preds = torch.max(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:32.279223Z","iopub.execute_input":"2024-12-11T14:10:32.279889Z","iopub.status.idle":"2024-12-11T14:10:32.285554Z","shell.execute_reply.started":"2024-12-11T14:10:32.279853Z","shell.execute_reply":"2024-12-11T14:10:32.284503Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"input_size = 384  # Sentence embedding size\nnum_classes = len(set(labels))  # Number of unique classes\nkernel_sizes = [1]  # Different filter sizes\nnum_filters = 256  # Number of filters per kernel size\ndropout = 0.6\nlearning_rate = 0.001\nepochs = 50\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize TextCNN\nmodel = TextCNN(input_size, num_classes, kernel_sizes, num_filters, dropout).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:35.669234Z","iopub.execute_input":"2024-12-11T14:10:35.669639Z","iopub.status.idle":"2024-12-11T14:10:35.678634Z","shell.execute_reply.started":"2024-12-11T14:10:35.669608Z","shell.execute_reply":"2024-12-11T14:10:35.677859Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Train and validate\ntrain_model(model, train_dataloader, optimizer, criterion, epochs=epochs, save_path='textcnn.pth', scheduler=scheduler)\nval_model(model, val_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:10:38.939531Z","iopub.execute_input":"2024-12-11T14:10:38.940436Z","iopub.status.idle":"2024-12-11T14:11:49.787996Z","shell.execute_reply.started":"2024-12-11T14:10:38.940397Z","shell.execute_reply":"2024-12-11T14:11:49.787088Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/50], Loss: 1.0515, Accuracy: 70.10%\nEpoch [2/50], Loss: 0.7233, Accuracy: 74.54%\nEpoch [3/50], Loss: 0.6894, Accuracy: 75.62%\nEpoch [4/50], Loss: 0.6696, Accuracy: 75.98%\nEpoch [5/50], Loss: 0.6566, Accuracy: 76.48%\nEpoch [6/50], Loss: 0.6430, Accuracy: 76.79%\nEpoch [7/50], Loss: 0.6352, Accuracy: 77.04%\nEpoch [8/50], Loss: 0.6218, Accuracy: 77.37%\nEpoch [9/50], Loss: 0.6146, Accuracy: 77.98%\nEpoch [10/50], Loss: 0.6008, Accuracy: 78.08%\nEpoch [11/50], Loss: 0.5877, Accuracy: 79.06%\nEpoch [12/50], Loss: 0.5826, Accuracy: 78.72%\nEpoch [13/50], Loss: 0.5761, Accuracy: 79.38%\nEpoch [14/50], Loss: 0.5712, Accuracy: 79.33%\nEpoch [15/50], Loss: 0.5632, Accuracy: 79.97%\nEpoch [16/50], Loss: 0.5585, Accuracy: 80.14%\nEpoch [17/50], Loss: 0.5545, Accuracy: 80.21%\nEpoch [18/50], Loss: 0.5503, Accuracy: 80.25%\nEpoch [19/50], Loss: 0.5477, Accuracy: 80.59%\nEpoch [20/50], Loss: 0.5416, Accuracy: 80.69%\nEpoch [21/50], Loss: 0.5285, Accuracy: 81.12%\nEpoch [22/50], Loss: 0.5278, Accuracy: 81.15%\nEpoch [23/50], Loss: 0.5232, Accuracy: 81.37%\nEpoch [24/50], Loss: 0.5219, Accuracy: 81.42%\nEpoch [25/50], Loss: 0.5164, Accuracy: 81.64%\nEpoch [26/50], Loss: 0.5166, Accuracy: 81.74%\nEpoch [27/50], Loss: 0.5130, Accuracy: 81.96%\nEpoch [28/50], Loss: 0.5121, Accuracy: 82.10%\nEpoch [29/50], Loss: 0.5086, Accuracy: 82.22%\nEpoch [30/50], Loss: 0.5032, Accuracy: 81.98%\nEpoch [31/50], Loss: 0.5008, Accuracy: 82.36%\nEpoch [32/50], Loss: 0.4981, Accuracy: 82.37%\nEpoch [33/50], Loss: 0.4953, Accuracy: 82.42%\nEpoch [34/50], Loss: 0.4912, Accuracy: 82.54%\nEpoch [35/50], Loss: 0.4925, Accuracy: 82.77%\nEpoch [36/50], Loss: 0.4916, Accuracy: 82.63%\nEpoch [37/50], Loss: 0.4930, Accuracy: 82.42%\nEpoch [38/50], Loss: 0.4885, Accuracy: 82.74%\nEpoch [39/50], Loss: 0.4881, Accuracy: 82.83%\nEpoch [40/50], Loss: 0.4870, Accuracy: 82.89%\nEpoch [41/50], Loss: 0.4832, Accuracy: 82.94%\nEpoch [42/50], Loss: 0.4804, Accuracy: 83.08%\nEpoch [43/50], Loss: 0.4806, Accuracy: 83.02%\nEpoch [44/50], Loss: 0.4833, Accuracy: 82.94%\nEpoch [45/50], Loss: 0.4813, Accuracy: 82.96%\nEpoch [46/50], Loss: 0.4783, Accuracy: 83.31%\nEpoch [47/50], Loss: 0.4818, Accuracy: 83.04%\nEpoch [48/50], Loss: 0.4758, Accuracy: 83.40%\nEpoch [49/50], Loss: 0.4764, Accuracy: 83.30%\nEpoch [50/50], Loss: 0.4798, Accuracy: 83.31%\nTraining complete.\nModel saved to textcnn.pth\nValidation Accuracy: 76.33%\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0.7633053221288515"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"df_test=pd.read_csv('/kaggle/input/nn-text-classfication/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:13:31.280011Z","iopub.execute_input":"2024-12-11T14:13:31.281175Z","iopub.status.idle":"2024-12-11T14:13:31.362070Z","shell.execute_reply.started":"2024-12-11T14:13:31.281133Z","shell.execute_reply":"2024-12-11T14:13:31.361334Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"df_test['Discussion'] = df_test['Discussion'].fillna('No Text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:13:32.637089Z","iopub.execute_input":"2024-12-11T14:13:32.637475Z","iopub.status.idle":"2024-12-11T14:13:32.644793Z","shell.execute_reply.started":"2024-12-11T14:13:32.637442Z","shell.execute_reply":"2024-12-11T14:13:32.643811Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf_test['Discussion'] = df_test['Discussion'].apply(replace_dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:13:33.832718Z","iopub.execute_input":"2024-12-11T14:13:33.833403Z","iopub.status.idle":"2024-12-11T14:13:34.020021Z","shell.execute_reply.started":"2024-12-11T14:13:33.833369Z","shell.execute_reply":"2024-12-11T14:13:34.019262Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Generate embeddings for the dataset\nembeddings_test = model_new.encode(df_test['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n\n# Save embeddings to a file\nnp.save('news_embeddings_train.npy', embeddings_test)\n\nprint(\"Embeddings and labels saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:13:36.268970Z","iopub.execute_input":"2024-12-11T14:13:36.269355Z","iopub.status.idle":"2024-12-11T14:13:41.623729Z","shell.execute_reply.started":"2024-12-11T14:13:36.269319Z","shell.execute_reply":"2024-12-11T14:13:41.622776Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/330 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235ecc4dcca547728508b2d7b02069fd"}},"metadata":{}},{"name":"stdout","text":"Embeddings and labels saved successfully!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, sentences, sample_ids):\n        # Ensure input embeddings are treated as sequences with one channel\n        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32).unsqueeze(0) for x in sentences])\n        self.sample_ids = torch.tensor(sample_ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        return self.sentences[idx], self.sample_ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:14:29.954749Z","iopub.execute_input":"2024-12-11T14:14:29.955087Z","iopub.status.idle":"2024-12-11T14:14:29.960863Z","shell.execute_reply.started":"2024-12-11T14:14:29.955054Z","shell.execute_reply":"2024-12-11T14:14:29.959806Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"test_dataset = CustomDataset(embeddings_test, df_test['SampleID'])\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:14:31.558906Z","iopub.execute_input":"2024-12-11T14:14:31.559625Z","iopub.status.idle":"2024-12-11T14:14:31.721244Z","shell.execute_reply.started":"2024-12-11T14:14:31.559585Z","shell.execute_reply":"2024-12-11T14:14:31.720525Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"save_csv_path = '/kaggle/working/predictions_textcnn1.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:14:32.872118Z","iopub.execute_input":"2024-12-11T14:14:32.872515Z","iopub.status.idle":"2024-12-11T14:14:32.876997Z","shell.execute_reply.started":"2024-12-11T14:14:32.872479Z","shell.execute_reply":"2024-12-11T14:14:32.875914Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def test_model(model, val_dataloader, save_csv_path='predictions.csv', device='cuda'):\n    model.eval()  # Set model to evaluation mode\n    all_preds = []\n    sample_ids = []  # To store sample IDs\n\n    with torch.no_grad():\n        for sentences, ids in val_dataloader:  # Extract sentences and IDs from DataLoader\n            sentences = sentences.float().to(device)  # Move sentences to GPU (or CPU if needed)\n            outputs = model(sentences)\n            _, preds = torch.max(outputs, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())  # Move predictions back to CPU\n            sample_ids.extend(ids.numpy())  # Collect the sample IDs\n\n    # Save predictions to a CSV file\n    predictions_df = pd.DataFrame({\n        'SampleID': sample_ids,\n        'Category': all_preds\n    })\n    predictions_df.to_csv(save_csv_path, index=False)\n    print(f\"Predictions saved to {save_csv_path}\")\n    \n    return predictions_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:14:34.902100Z","iopub.execute_input":"2024-12-11T14:14:34.902707Z","iopub.status.idle":"2024-12-11T14:14:34.908696Z","shell.execute_reply.started":"2024-12-11T14:14:34.902671Z","shell.execute_reply":"2024-12-11T14:14:34.907867Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"test_model(model, test_dataloader, save_csv_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T14:14:36.878180Z","iopub.execute_input":"2024-12-11T14:14:36.878616Z","iopub.status.idle":"2024-12-11T14:14:37.200828Z","shell.execute_reply.started":"2024-12-11T14:14:36.878578Z","shell.execute_reply":"2024-12-11T14:14:37.199918Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to /kaggle/working/predictions_textcnn1.csv\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"       SampleID  Category\n0             1         3\n1             2         0\n2             3         1\n3             4         4\n4             5         3\n...         ...       ...\n10552     10553         4\n10553     10554         3\n10554     10555         3\n10555     10556         0\n10556     10557         2\n\n[10557 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10552</th>\n      <td>10553</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10553</th>\n      <td>10554</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10554</th>\n      <td>10555</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10555</th>\n      <td>10556</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10556</th>\n      <td>10557</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>10557 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":34}]}