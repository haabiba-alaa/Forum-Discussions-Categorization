{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10089847,"sourceType":"datasetVersion","datasetId":6221550},{"sourceId":10103467,"sourceType":"datasetVersion","datasetId":6231957},{"sourceId":10114239,"sourceType":"datasetVersion","datasetId":6240198}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport torch\nimport pandas as pd\nfrom transformers import BertTokenizer, BertModel\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score\nimport ast\nimport torch.optim as optim\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:30:14.400777Z","iopub.execute_input":"2024-12-15T17:30:14.401695Z","iopub.status.idle":"2024-12-15T17:30:35.228095Z","shell.execute_reply.started":"2024-12-15T17:30:14.401651Z","shell.execute_reply":"2024-12-15T17:30:35.227114Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:29:51.048738Z","iopub.execute_input":"2024-12-15T17:29:51.049094Z","iopub.status.idle":"2024-12-15T17:30:01.531675Z","shell.execute_reply.started":"2024-12-15T17:29:51.049044Z","shell.execute_reply":"2024-12-15T17:30:01.530119Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/nn-text-classfication/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:30:47.230704Z","iopub.execute_input":"2024-12-15T17:30:47.231425Z","iopub.status.idle":"2024-12-15T17:30:47.460829Z","shell.execute_reply.started":"2024-12-15T17:30:47.231388Z","shell.execute_reply":"2024-12-15T17:30:47.460040Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"model_new = SentenceTransformer('all-mpnet-base-v2', device='cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:30:48.612045Z","iopub.execute_input":"2024-12-15T17:30:48.612915Z","iopub.status.idle":"2024-12-15T17:30:54.952027Z","shell.execute_reply.started":"2024-12-15T17:30:48.612878Z","shell.execute_reply":"2024-12-15T17:30:54.951266Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"334e3372c5c4428bb198a600a0c12bc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"129896768b7040659b0291a8cabf5067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"968acdc8488b4096b423cb5569abc53f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f490ad9b440841d8a94d9d14ac9f56d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba4baa6cac3d403698e8bb380c2525fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67c4163555414124aae68c4b2a03d5b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"955b865460d34b24967e9503ba049094"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"744a4dcf36a641dbb66cc672c7db44a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"792e3f94fdf843deaba07a3ca6943a6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"247f1f09008d452eac5c3f96d9cde620"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75c5a3f0f2ff49ee9704f89df44aa826"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:30:56.823753Z","iopub.execute_input":"2024-12-15T17:30:56.824105Z","iopub.status.idle":"2024-12-15T17:30:56.841208Z","shell.execute_reply.started":"2024-12-15T17:30:56.824076Z","shell.execute_reply":"2024-12-15T17:30:56.839952Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   SampleID                                         Discussion  Category\n0         1  Without sitting down and doing it manually, yo...    Sports\n1         2               All your Search ends with this link.      STEM\n2         3  No, the program you're using is made to be com...      STEM\n3         4  Mike Woicik\\n\\nThe correct answer is: Mike Woi...    Sports\n4         5  No, but not because of why you might think. Wh...  Politics","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Discussion</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Without sitting down and doing it manually, yo...</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>All your Search ends with this link.</td>\n      <td>STEM</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>No, the program you're using is made to be com...</td>\n      <td>STEM</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Mike Woicik\\n\\nThe correct answer is: Mike Woi...</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>No, but not because of why you might think. Wh...</td>\n      <td>Politics</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df_train['Discussion'] = df_train['Discussion'].fillna('No Text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:30:59.434848Z","iopub.execute_input":"2024-12-15T17:30:59.435580Z","iopub.status.idle":"2024-12-15T17:30:59.446714Z","shell.execute_reply.started":"2024-12-15T17:30:59.435543Z","shell.execute_reply":"2024-12-15T17:30:59.445634Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf_train['Discussion'] = df_train['Discussion'].apply(replace_dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:31:00.710192Z","iopub.execute_input":"2024-12-15T17:31:00.710580Z","iopub.status.idle":"2024-12-15T17:31:01.385426Z","shell.execute_reply.started":"2024-12-15T17:31:00.710550Z","shell.execute_reply":"2024-12-15T17:31:01.384602Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Generate embeddings for the dataset\nembeddings_train = model_new.encode(df_train['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n\n# Save embeddings to a file\nnp.save('news_embeddings_train.npy', embeddings_train)\n\n# Save corresponding labels\ndf_train['Category'].to_csv('news_labels.csv', index=False)\n\nprint(\"Embeddings and labels saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:31:02.982825Z","iopub.execute_input":"2024-12-15T17:31:02.983201Z","iopub.status.idle":"2024-12-15T17:32:23.800581Z","shell.execute_reply.started":"2024-12-15T17:31:02.983167Z","shell.execute_reply":"2024-12-15T17:32:23.799486Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/781 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2679db0a69b4a30832065cb982772af"}},"metadata":{}},{"name":"stdout","text":"Embeddings and labels saved successfully!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"label_mapping = {\n    'Politics': 0,\n    'Sports': 1,\n    'Media': 2,\n    'Market & Economy': 3,\n    'STEM': 4\n}\ndf_train['Category']=df_train['Category'].map(label_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:32:32.618374Z","iopub.execute_input":"2024-12-15T17:32:32.619099Z","iopub.status.idle":"2024-12-15T17:32:32.628835Z","shell.execute_reply.started":"2024-12-15T17:32:32.619062Z","shell.execute_reply":"2024-12-15T17:32:32.627741Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"labels = list(df_train['Category'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:32:34.011816Z","iopub.execute_input":"2024-12-15T17:32:34.012749Z","iopub.status.idle":"2024-12-15T17:32:34.018619Z","shell.execute_reply.started":"2024-12-15T17:32:34.012707Z","shell.execute_reply":"2024-12-15T17:32:34.017666Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, sentences, labels):\n        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32).unsqueeze(0) for x in sentences])\n        self.labels = torch.tensor(labels, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        return self.sentences[idx], self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:32:35.927994Z","iopub.execute_input":"2024-12-15T17:32:35.928771Z","iopub.status.idle":"2024-12-15T17:32:35.934477Z","shell.execute_reply.started":"2024-12-15T17:32:35.928724Z","shell.execute_reply":"2024-12-15T17:32:35.933440Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(embeddings_train, labels, test_size=0.2, random_state=42)\n\ntrain_dataset = TextDataset(X_train, y_train)\nval_dataset = TextDataset(X_val, y_val)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:32:37.277136Z","iopub.execute_input":"2024-12-15T17:32:37.277566Z","iopub.status.idle":"2024-12-15T17:32:37.775997Z","shell.execute_reply.started":"2024-12-15T17:32:37.277530Z","shell.execute_reply":"2024-12-15T17:32:37.775168Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"for batch in train_dataloader:\n    sentences, labels = batch\n    print(f\"Train batch size: {sentences.size(0)}\")\n    print(f\"Sentence shape: {sentences.shape}\")\n    print(f\"Labels shape: {labels.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:32:39.711873Z","iopub.execute_input":"2024-12-15T17:32:39.712755Z","iopub.status.idle":"2024-12-15T17:32:39.723104Z","shell.execute_reply.started":"2024-12-15T17:32:39.712707Z","shell.execute_reply":"2024-12-15T17:32:39.722125Z"}},"outputs":[{"name":"stdout","text":"Train batch size: 32\nSentence shape: torch.Size([32, 1, 768])\nLabels shape: torch.Size([32])\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"class TextCNN(nn.Module):\n    \"\"\"\n    TextCNN model for text classification.\n    \"\"\"\n    def __init__(self, input_size, num_classes, kernel_sizes, num_filters, dropout=0.5):\n        super(TextCNN, self).__init__()\n        self.convs = nn.ModuleList([\n            nn.Sequential(\n                nn.Conv2d(1, num_filters, (k, input_size)),\n                nn.ReLU(inplace=True),\n                nn.BatchNorm2d(num_filters)\n            )\n            for k in kernel_sizes\n        ])\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(len(kernel_sizes) * num_filters, num_classes)\n        self.init_weights()\n\n    def init_weights(self):\n        for conv in self.convs:\n            nn.init.kaiming_uniform_(conv[0].weight, nonlinearity='relu')\n        nn.init.xavier_uniform_(self.fc.weight)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # Add channel dimension [batch_size, 1, sequence_length, input_size]\n        conv_outputs = [torch.relu(conv(x)).squeeze(3) for conv in self.convs]  # [batch_size, num_filters, seq_len]\n        pooled_outputs = [torch.max(output, dim=2)[0] for output in conv_outputs]  # Max Pooling\n        out = torch.cat(pooled_outputs, dim=1)  # Concatenate along the feature dimension\n        out = self.dropout(out)\n        out = self.fc(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:32:44.950341Z","iopub.execute_input":"2024-12-15T17:32:44.950708Z","iopub.status.idle":"2024-12-15T17:32:44.959476Z","shell.execute_reply.started":"2024-12-15T17:32:44.950679Z","shell.execute_reply":"2024-12-15T17:32:44.958308Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def train_model(\n    model, train_dataloader, optimizer, criterion, epochs=5, save_path='model.pth', scheduler=None\n):\n    model.train()\n    best_acc = 0.0\n\n    for epoch in range(epochs):\n        running_loss = 0.0\n        all_preds = []\n        all_labels = []\n\n        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n        for sentences, labels in progress_bar:\n            sentences = sentences.float().to(device)\n            labels = labels.long().to(device)\n\n            optimizer.zero_grad()\n            outputs = model(sentences)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # Gradient clipping\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, preds = torch.max(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n        if scheduler:\n            scheduler.step()\n\n        epoch_loss = running_loss / len(train_dataloader)\n        epoch_acc = accuracy_score(all_labels, all_preds) * 100\n\n        print(\n            f\"Epoch [{epoch+1}/{epochs}] \"\n            f\"Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\"\n        )\n\n        # Save the best model\n        if epoch_acc > best_acc:\n            best_acc = epoch_acc\n            torch.save(model.state_dict(), save_path)\n            print(f\"Model saved to {save_path} (Best Accuracy: {best_acc:.2f}%)\")\n\n    print(\"Training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:33:32.934022Z","iopub.execute_input":"2024-12-15T17:33:32.934953Z","iopub.status.idle":"2024-12-15T17:33:32.943264Z","shell.execute_reply.started":"2024-12-15T17:33:32.934912Z","shell.execute_reply":"2024-12-15T17:33:32.942276Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Validation function\ndef val_model(model, val_dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for sentences, labels in val_dataloader:\n            sentences = sentences.float().to(device)\n            labels = labels.long().to(device)\n            outputs = model(sentences)\n            _, preds = torch.max(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:32:50.580986Z","iopub.execute_input":"2024-12-15T17:32:50.581400Z","iopub.status.idle":"2024-12-15T17:32:50.587671Z","shell.execute_reply.started":"2024-12-15T17:32:50.581364Z","shell.execute_reply":"2024-12-15T17:32:50.586641Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"input_size = 768  # Sentence embedding size\nnum_classes = len(set(labels))  # Number of unique classes\nkernel_sizes = [1]  # Different filter sizes\nnum_filters = 128  # Number of filters per kernel size\ndropout = 0.7\nlearning_rate = 0.001\nepochs = 30\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize TextCNN\nmodel = TextCNN(input_size, num_classes, kernel_sizes, num_filters, dropout).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:32:55.532416Z","iopub.execute_input":"2024-12-15T17:32:55.533054Z","iopub.status.idle":"2024-12-15T17:32:55.544555Z","shell.execute_reply.started":"2024-12-15T17:32:55.533015Z","shell.execute_reply":"2024-12-15T17:32:55.543553Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Train and validate\ntrain_model(model, train_dataloader, optimizer, criterion, epochs=epochs, save_path='textcnn.pth', scheduler=scheduler)\nval_model(model, val_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:33:36.421683Z","iopub.execute_input":"2024-12-15T17:33:36.422056Z","iopub.status.idle":"2024-12-15T17:34:27.026567Z","shell.execute_reply.started":"2024-12-15T17:33:36.422024Z","shell.execute_reply":"2024-12-15T17:34:27.025607Z"}},"outputs":[{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch [1/30] Loss: 1.1490 | Accuracy: 64.36%\nModel saved to textcnn.pth (Best Accuracy: 64.36%)\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch [2/30] Loss: 0.7514 | Accuracy: 74.03%\nModel saved to textcnn.pth (Best Accuracy: 74.03%)\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch [3/30] Loss: 0.7065 | Accuracy: 75.33%\nModel saved to textcnn.pth (Best Accuracy: 75.33%)\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch [4/30] Loss: 0.6819 | Accuracy: 76.15%\nModel saved to textcnn.pth (Best Accuracy: 76.15%)\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch [5/30] Loss: 0.6595 | Accuracy: 76.52%\nModel saved to textcnn.pth (Best Accuracy: 76.52%)\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch [6/30] Loss: 0.6478 | Accuracy: 76.78%\nModel saved to textcnn.pth (Best Accuracy: 76.78%)\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch [7/30] Loss: 0.6361 | Accuracy: 77.29%\nModel saved to textcnn.pth (Best Accuracy: 77.29%)\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch [8/30] Loss: 0.6238 | Accuracy: 77.55%\nModel saved to textcnn.pth (Best Accuracy: 77.55%)\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch [9/30] Loss: 0.6218 | Accuracy: 77.72%\nModel saved to textcnn.pth (Best Accuracy: 77.72%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [10/30] Loss: 0.6061 | Accuracy: 78.25%\nModel saved to textcnn.pth (Best Accuracy: 78.25%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [11/30] Loss: 0.5836 | Accuracy: 79.00%\nModel saved to textcnn.pth (Best Accuracy: 79.00%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [12/30] Loss: 0.5714 | Accuracy: 79.36%\nModel saved to textcnn.pth (Best Accuracy: 79.36%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [13/30] Loss: 0.5629 | Accuracy: 79.48%\nModel saved to textcnn.pth (Best Accuracy: 79.48%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [14/30] Loss: 0.5523 | Accuracy: 79.79%\nModel saved to textcnn.pth (Best Accuracy: 79.79%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [15/30] Loss: 0.5433 | Accuracy: 80.38%\nModel saved to textcnn.pth (Best Accuracy: 80.38%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [16/30] Loss: 0.5416 | Accuracy: 80.12%\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [17/30] Loss: 0.5349 | Accuracy: 80.50%\nModel saved to textcnn.pth (Best Accuracy: 80.50%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [18/30] Loss: 0.5286 | Accuracy: 80.63%\nModel saved to textcnn.pth (Best Accuracy: 80.63%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [19/30] Loss: 0.5216 | Accuracy: 80.81%\nModel saved to textcnn.pth (Best Accuracy: 80.81%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [20/30] Loss: 0.5187 | Accuracy: 81.12%\nModel saved to textcnn.pth (Best Accuracy: 81.12%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [21/30] Loss: 0.5086 | Accuracy: 81.16%\nModel saved to textcnn.pth (Best Accuracy: 81.16%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [22/30] Loss: 0.4906 | Accuracy: 81.68%\nModel saved to textcnn.pth (Best Accuracy: 81.68%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [23/30] Loss: 0.4922 | Accuracy: 81.81%\nModel saved to textcnn.pth (Best Accuracy: 81.81%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [24/30] Loss: 0.4829 | Accuracy: 82.29%\nModel saved to textcnn.pth (Best Accuracy: 82.29%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [25/30] Loss: 0.4772 | Accuracy: 82.33%\nModel saved to textcnn.pth (Best Accuracy: 82.33%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [26/30] Loss: 0.4741 | Accuracy: 82.44%\nModel saved to textcnn.pth (Best Accuracy: 82.44%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [27/30] Loss: 0.4671 | Accuracy: 82.58%\nModel saved to textcnn.pth (Best Accuracy: 82.58%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [28/30] Loss: 0.4672 | Accuracy: 82.60%\nModel saved to textcnn.pth (Best Accuracy: 82.60%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [29/30] Loss: 0.4662 | Accuracy: 82.83%\nModel saved to textcnn.pth (Best Accuracy: 82.83%)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch [30/30] Loss: 0.4599 | Accuracy: 82.88%\nModel saved to textcnn.pth (Best Accuracy: 82.88%)\nTraining complete.\nValidation Accuracy: 78.57%\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0.7857142857142857"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"df_test=pd.read_csv('/kaggle/input/nn-text-classfication/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:34:32.885246Z","iopub.execute_input":"2024-12-15T17:34:32.885656Z","iopub.status.idle":"2024-12-15T17:34:32.983882Z","shell.execute_reply.started":"2024-12-15T17:34:32.885621Z","shell.execute_reply":"2024-12-15T17:34:32.982990Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"df_test['Discussion'] = df_test['Discussion'].fillna('No Text')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:34:34.411116Z","iopub.execute_input":"2024-12-15T17:34:34.411489Z","iopub.status.idle":"2024-12-15T17:34:34.419012Z","shell.execute_reply.started":"2024-12-15T17:34:34.411456Z","shell.execute_reply":"2024-12-15T17:34:34.417908Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def replace_dates(text):\n    date_pattern = r'\\b(\\d{1,2}-[A-Za-z]{3}|\\b[A-Za-z]+ \\d{1,2}(\\w{2})?)\\b'\n    return re.sub(date_pattern, '[DATE]', text)\n\ndf_test['Discussion'] = df_test['Discussion'].apply(replace_dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:34:36.178572Z","iopub.execute_input":"2024-12-15T17:34:36.179368Z","iopub.status.idle":"2024-12-15T17:34:36.357033Z","shell.execute_reply.started":"2024-12-15T17:34:36.179334Z","shell.execute_reply":"2024-12-15T17:34:36.356286Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Generate embeddings for the dataset\nembeddings_test = model_new.encode(df_test['Discussion'].tolist(), convert_to_tensor=True).cpu().numpy()\n\n# Save embeddings to a file\nnp.save('news_embeddings_train.npy', embeddings_test)\n\nprint(\"Embeddings and labels saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:34:38.170480Z","iopub.execute_input":"2024-12-15T17:34:38.171394Z","iopub.status.idle":"2024-12-15T17:35:12.631763Z","shell.execute_reply.started":"2024-12-15T17:34:38.171355Z","shell.execute_reply":"2024-12-15T17:35:12.630748Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/330 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f533214b122a4460a6bb673f52733bb6"}},"metadata":{}},{"name":"stdout","text":"Embeddings and labels saved successfully!\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, sentences, sample_ids):\n        self.sentences = torch.stack([torch.tensor(x, dtype=torch.float32).unsqueeze(0) for x in sentences])\n        self.sample_ids = torch.tensor(sample_ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        return self.sentences[idx], self.sample_ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:35:15.034112Z","iopub.execute_input":"2024-12-15T17:35:15.034485Z","iopub.status.idle":"2024-12-15T17:35:15.040150Z","shell.execute_reply.started":"2024-12-15T17:35:15.034453Z","shell.execute_reply":"2024-12-15T17:35:15.039228Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"test_dataset = CustomDataset(embeddings_test, df_test['SampleID'])\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:35:16.650627Z","iopub.execute_input":"2024-12-15T17:35:16.651451Z","iopub.status.idle":"2024-12-15T17:35:16.843402Z","shell.execute_reply.started":"2024-12-15T17:35:16.651413Z","shell.execute_reply":"2024-12-15T17:35:16.842609Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"save_csv_path = '/kaggle/working/predictions_text_trial.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:35:19.443477Z","iopub.execute_input":"2024-12-15T17:35:19.443872Z","iopub.status.idle":"2024-12-15T17:35:19.448559Z","shell.execute_reply.started":"2024-12-15T17:35:19.443839Z","shell.execute_reply":"2024-12-15T17:35:19.447439Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def test_model(model, val_dataloader, save_csv_path='predictions.csv', device='cuda'):\n    model.eval()  # Set model to evaluation mode\n    all_preds = []\n    sample_ids = []  # To store sample IDs\n\n    with torch.no_grad():\n        for sentences, ids in val_dataloader:  # Extract sentences and IDs from DataLoader\n            sentences = sentences.float().to(device)  # Move sentences to GPU (or CPU if needed)\n            outputs = model(sentences)\n            _, preds = torch.max(outputs, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())  # Move predictions back to CPU\n            sample_ids.extend(ids.numpy())  # Collect the sample IDs\n\n    # Save predictions to a CSV file\n    predictions_df = pd.DataFrame({\n        'SampleID': sample_ids,\n        'Category': all_preds\n    })\n    predictions_df.to_csv(save_csv_path, index=False)\n    print(f\"Predictions saved to {save_csv_path}\")\n    \n    return predictions_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:35:21.346089Z","iopub.execute_input":"2024-12-15T17:35:21.346897Z","iopub.status.idle":"2024-12-15T17:35:21.353273Z","shell.execute_reply.started":"2024-12-15T17:35:21.346855Z","shell.execute_reply":"2024-12-15T17:35:21.352168Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"test_model(model, test_dataloader, save_csv_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:35:23.385352Z","iopub.execute_input":"2024-12-15T17:35:23.386408Z","iopub.status.idle":"2024-12-15T17:35:23.737140Z","shell.execute_reply.started":"2024-12-15T17:35:23.386361Z","shell.execute_reply":"2024-12-15T17:35:23.736187Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to /kaggle/working/predictions_text_trial.csv\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"       SampleID  Category\n0             1         3\n1             2         0\n2             3         1\n3             4         4\n4             5         3\n...         ...       ...\n10552     10553         4\n10553     10554         3\n10554     10555         3\n10555     10556         3\n10556     10557         2\n\n[10557 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10552</th>\n      <td>10553</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10553</th>\n      <td>10554</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10554</th>\n      <td>10555</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10555</th>\n      <td>10556</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10556</th>\n      <td>10557</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>10557 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":28}]}