{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10103467,"sourceType":"datasetVersion","datasetId":6231957},{"sourceId":10114239,"sourceType":"datasetVersion","datasetId":6240198}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:17:39.747318Z","iopub.execute_input":"2024-12-10T14:17:39.747926Z","iopub.status.idle":"2024-12-10T14:17:40.194311Z","shell.execute_reply.started":"2024-12-10T14:17:39.747873Z","shell.execute_reply":"2024-12-10T14:17:40.193090Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/test-embeddings/second_batch_embeddings.csv\n/kaggle/input/final-embeddings/second_batch_embeddings.csv\n/kaggle/input/final-embeddings/Final_BERT_Embeddings_NN.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import load_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:17:40.196650Z","iopub.execute_input":"2024-12-10T14:17:40.197134Z","iopub.status.idle":"2024-12-10T14:17:44.150473Z","shell.execute_reply.started":"2024-12-10T14:17:40.197095Z","shell.execute_reply":"2024-12-10T14:17:44.149128Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load dataset\ntrain_path = \"/kaggle/input/final-embeddings/Final_BERT_Embeddings_NN.csv\"\n\n\n# Read the datasets\ntrain_df = pd.read_csv(train_path)\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:17:44.152011Z","iopub.execute_input":"2024-12-10T14:17:44.152686Z","iopub.status.idle":"2024-12-10T14:17:48.163761Z","shell.execute_reply.started":"2024-12-10T14:17:44.152636Z","shell.execute_reply":"2024-12-10T14:17:48.162195Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"       SampleID          Category  \\\n0             1            Sports   \n1             2              STEM   \n2             3              STEM   \n3             4            Sports   \n4             5          Politics   \n...         ...               ...   \n24984     24985            Sports   \n24985     24986  Market & Economy   \n24986     24987  Market & Economy   \n24987     24988          Politics   \n24988     24989             Media   \n\n                                      Sentence_Embedding  \n0      [0.10802699625492096, -0.29468590021133423, 0....  \n1      [0.15774837136268616, -0.27033138275146484, 0....  \n2      [0.09479232132434845, -0.026669710874557495, 0...  \n3      [-0.05896478891372681, 0.03615675866603851, 0....  \n4      [0.12355563789606094, -0.0836852490901947, -0....  \n...                                                  ...  \n24984  [0.04971267655491829, -0.2155923992395401, 0.3...  \n24985  [0.4561083912849426, -0.05284585803747177, 0.2...  \n24986  [0.2979573607444763, -0.21786299347877502, 0.1...  \n24987  [0.03884076699614525, 0.04084499180316925, 0.2...  \n24988  [-0.007423486560583115, -0.06878117471933365, ...  \n\n[24989 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Category</th>\n      <th>Sentence_Embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Sports</td>\n      <td>[0.10802699625492096, -0.29468590021133423, 0....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>STEM</td>\n      <td>[0.15774837136268616, -0.27033138275146484, 0....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>STEM</td>\n      <td>[0.09479232132434845, -0.026669710874557495, 0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Sports</td>\n      <td>[-0.05896478891372681, 0.03615675866603851, 0....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Politics</td>\n      <td>[0.12355563789606094, -0.0836852490901947, -0....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24984</th>\n      <td>24985</td>\n      <td>Sports</td>\n      <td>[0.04971267655491829, -0.2155923992395401, 0.3...</td>\n    </tr>\n    <tr>\n      <th>24985</th>\n      <td>24986</td>\n      <td>Market &amp; Economy</td>\n      <td>[0.4561083912849426, -0.05284585803747177, 0.2...</td>\n    </tr>\n    <tr>\n      <th>24986</th>\n      <td>24987</td>\n      <td>Market &amp; Economy</td>\n      <td>[0.2979573607444763, -0.21786299347877502, 0.1...</td>\n    </tr>\n    <tr>\n      <th>24987</th>\n      <td>24988</td>\n      <td>Politics</td>\n      <td>[0.03884076699614525, 0.04084499180316925, 0.2...</td>\n    </tr>\n    <tr>\n      <th>24988</th>\n      <td>24989</td>\n      <td>Media</td>\n      <td>[-0.007423486560583115, -0.06878117471933365, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24989 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Define label mapping for categories\nlabel_mapping = {\n    'Politics': 0,\n    'Sports': 1,\n    'Media': 2,\n    'Market & Economy': 3,\n    'STEM': 4\n}\n# Map the 'Category' column to numeric labels\ntrain_df['Category'] = train_df['Category'].map(label_mapping)\n\n\n# Split train data into train and validation sets (80/20 split)\nX_train, X_val, y_train, y_val = train_test_split(\n    np.array(train_df['Sentence_Embedding'].apply(eval).tolist()), \n    train_df['Category'], \n    test_size=0.2, \n    random_state=42\n)\n# Reshape the data to (samples, sequence_length, embedding_dim)\n# In this case, sequence_length = 1 (since each sentence has a single embedding)\nX_train = np.expand_dims(X_train, axis=1)  # Shape becomes (num_samples, 1, 768)\nX_val = np.expand_dims(X_val, axis=1)      # Shape becomes (num_samples, 1, 768)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:17:48.167519Z","iopub.execute_input":"2024-12-10T14:17:48.168068Z","iopub.status.idle":"2024-12-10T14:18:38.608446Z","shell.execute_reply.started":"2024-12-10T14:17:48.167933Z","shell.execute_reply":"2024-12-10T14:18:38.607249Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from keras.saving import register_keras_serializable\n\n\nclass TransformerBlock(layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.ff_dim = ff_dim\n        self.rate = rate\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output)\n        return self.layernorm2(out1 + ffn_output)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"embed_dim\": self.embed_dim,\n            \"num_heads\": self.num_heads,\n            \"ff_dim\": self.ff_dim,\n            \"rate\": self.rate\n        })\n        return config\n\n# Define Position Encoding Layer with Dynamic Embedding Sizes\n@register_keras_serializable()\nclass TokenAndPositionEmbedding(layers.Layer):\n    def __init__(self, maxlen, embed_dim, **kwargs):\n        super().__init__(**kwargs)\n        self.maxlen = maxlen\n        self.embed_dim = embed_dim\n        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-2]\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        return x + positions\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"maxlen\": self.maxlen,\n            \"embed_dim\": self.embed_dim\n        })\n        return config\n\n\n# Define the model\nembed_dim = 768  # Fixed embedding dimension for each token\nmaxlen = 16556  # Maximum sequence length for embeddings\nnum_heads = 2  # Number of attention heads\nff_dim = 32  # Hidden layer size in the feed-forward network inside transformer\n\n# Use Input(shape=(None,)) to allow for variable-length embeddings\ninputs = layers.Input(shape=(None, embed_dim))  # Fixed embedding dimension (768), variable sequence length\n\n# Embedding layer with position encoding\nembedding_layer = TokenAndPositionEmbedding(maxlen, embed_dim)\nx = embedding_layer(inputs)\n\n# Transformer block\ntransformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\nx = transformer_block(x)\n\n\n\n\n# Pooling and output layers\nx = layers.GlobalAveragePooling1D()(x)\nx = layers.Dropout(0.1)(x)\nx = layers.Dense(20, activation=\"relu\")(x)  # Assuming the model has an intermediate dense layer with 20 units\nx = layers.Dropout(0.1)(x)\noutputs = layers.Dense(5, activation=\"softmax\")(x)  # 5 classes for the output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:18:38.611770Z","iopub.execute_input":"2024-12-10T14:18:38.612410Z","iopub.status.idle":"2024-12-10T14:18:39.063653Z","shell.execute_reply.started":"2024-12-10T14:18:38.612352Z","shell.execute_reply":"2024-12-10T14:18:39.062125Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\n# Define the EarlyStopping callback\nearly_stopping = EarlyStopping(\n    monitor='val_loss',  # Monitor validation loss\n    patience=3,          # Number of epochs to wait before stopping if no improvement\n    restore_best_weights=True  # Restore the weights of the best epoch\n)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:18:39.065059Z","iopub.execute_input":"2024-12-10T14:18:39.065409Z","iopub.status.idle":"2024-12-10T14:18:39.108058Z","shell.execute_reply.started":"2024-12-10T14:18:39.065372Z","shell.execute_reply":"2024-12-10T14:18:39.106952Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ token_and_position_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │    \u001b[38;5;34m12,715,008\u001b[0m │\n│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m4,776,992\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │        \u001b[38;5;34m15,380\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m105\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ token_and_position_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,715,008</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,776,992</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,380</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,507,485\u001b[0m (66.79 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,507,485</span> (66.79 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,507,485\u001b[0m (66.79 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,507,485</span> (66.79 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:18:39.109513Z","iopub.execute_input":"2024-12-10T14:18:39.109975Z","iopub.status.idle":"2024-12-10T15:09:27.117335Z","shell.execute_reply.started":"2024-12-10T14:18:39.109925Z","shell.execute_reply":"2024-12-10T15:09:27.116385Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 489ms/step - accuracy: 0.4902 - loss: 1.2228 - val_accuracy: 0.7111 - val_loss: 0.7837\nEpoch 2/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 478ms/step - accuracy: 0.6829 - loss: 0.8325 - val_accuracy: 0.7241 - val_loss: 0.7491\nEpoch 3/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 487ms/step - accuracy: 0.7036 - loss: 0.7893 - val_accuracy: 0.7173 - val_loss: 0.7788\nEpoch 4/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 483ms/step - accuracy: 0.7160 - loss: 0.7611 - val_accuracy: 0.7299 - val_loss: 0.7219\nEpoch 5/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 491ms/step - accuracy: 0.7226 - loss: 0.7375 - val_accuracy: 0.7211 - val_loss: 0.7617\nEpoch 6/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 490ms/step - accuracy: 0.7251 - loss: 0.7313 - val_accuracy: 0.7195 - val_loss: 0.7600\nEpoch 7/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 488ms/step - accuracy: 0.7327 - loss: 0.7300 - val_accuracy: 0.7223 - val_loss: 0.7533\nEpoch 8/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 488ms/step - accuracy: 0.7321 - loss: 0.7223 - val_accuracy: 0.7323 - val_loss: 0.7346\nEpoch 9/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 489ms/step - accuracy: 0.7401 - loss: 0.6978 - val_accuracy: 0.7301 - val_loss: 0.7165\nEpoch 10/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 486ms/step - accuracy: 0.7397 - loss: 0.6918 - val_accuracy: 0.7273 - val_loss: 0.7254\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/test-embeddings/second_batch_embeddings.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T15:09:28.091352Z","iopub.execute_input":"2024-12-10T15:09:28.091776Z","iopub.status.idle":"2024-12-10T15:09:32.303642Z","shell.execute_reply.started":"2024-12-10T15:09:28.091739Z","shell.execute_reply":"2024-12-10T15:09:32.302061Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T15:09:32.305126Z","iopub.execute_input":"2024-12-10T15:09:32.305491Z","iopub.status.idle":"2024-12-10T15:09:32.319330Z","shell.execute_reply.started":"2024-12-10T15:09:32.305428Z","shell.execute_reply":"2024-12-10T15:09:32.318181Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"       SampleID                                 Sentence_Embedding\n0             1  [0.15690432488918304, -0.060619909316301346, 0...\n1             2  [0.3401837944984436, -0.2515227794647217, 0.17...\n2             3  [0.09620901942253113, -0.008898760192096233, -...\n3             4  [0.27392739057540894, -0.07054565101861954, 0....\n4             5  [0.19433511793613434, -0.1849549561738968, 0.2...\n...         ...                                                ...\n10552     10553  [0.1671169400215149, -0.24635660648345947, 0.4...\n10553     10554  [0.1798195242881775, 0.031179074198007584, 0.0...\n10554     10555  [0.05961940437555313, -0.2453116476535797, 0.4...\n10555     10556  [0.390685498714447, -0.009291000664234161, 0.2...\n10556     10557  [0.3000105023384094, -0.1875845342874527, 0.30...\n\n[10557 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SampleID</th>\n      <th>Sentence_Embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[0.15690432488918304, -0.060619909316301346, 0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[0.3401837944984436, -0.2515227794647217, 0.17...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[0.09620901942253113, -0.008898760192096233, -...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[0.27392739057540894, -0.07054565101861954, 0....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[0.19433511793613434, -0.1849549561738968, 0.2...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10552</th>\n      <td>10553</td>\n      <td>[0.1671169400215149, -0.24635660648345947, 0.4...</td>\n    </tr>\n    <tr>\n      <th>10553</th>\n      <td>10554</td>\n      <td>[0.1798195242881775, 0.031179074198007584, 0.0...</td>\n    </tr>\n    <tr>\n      <th>10554</th>\n      <td>10555</td>\n      <td>[0.05961940437555313, -0.2453116476535797, 0.4...</td>\n    </tr>\n    <tr>\n      <th>10555</th>\n      <td>10556</td>\n      <td>[0.390685498714447, -0.009291000664234161, 0.2...</td>\n    </tr>\n    <tr>\n      <th>10556</th>\n      <td>10557</td>\n      <td>[0.3000105023384094, -0.1875845342874527, 0.30...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10557 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport ast\n\n# Check the type of embeddings in the first few rows\nprint(test_df['Sentence_Embedding'].head())\n\ndef process_embeddings(embedding):\n    # If the embedding is a string representation of a list, convert it\n    if isinstance(embedding, str):\n        try:\n            # Parse string representation to list\n            embedding = ast.literal_eval(embedding)\n        except Exception as e:\n            print(f\"Error converting string to list: {e}\")\n            return np.zeros(768)  # Default zero vector in case of error\n\n    # If it's already a numpy array, return it as is\n    if isinstance(embedding, np.ndarray):\n        return embedding\n    # If it's a list, convert it to a numpy array\n    elif isinstance(embedding, list):\n        return np.array(embedding)\n    else:\n        # If it's neither, print a message and return a default value\n        print(\"Unexpected embedding format\")\n        return np.zeros(768)  # default zero vector of length 768\n\n# Apply the processing function to ensure all embeddings are numpy arrays\nX_test = np.array(test_df['Sentence_Embedding'].apply(process_embeddings).tolist())\n\n# Ensure X_test is the correct shape (num_samples, 1, 768)\nX_test = np.expand_dims(X_test, axis=1)  # Shape becomes (num_samples, 1, 768)\n\n# Check the shape of X_test to confirm it is correct\nprint(X_test.shape)\n\n# Load the pre-trained model (replace with actual model path)\n\n# Make predictions with the model\ntest_predictions = model.predict(X_test)\n\n# Assuming it's a classification task and you want to get the predicted classes (using softmax output)\ntest_predicted_classes = test_predictions.argmax(axis=1)\n\n# Create a DataFrame to hold the predictions along with SampleID\ntest_predictions_df = pd.DataFrame({\n    'SampleID': test_df['SampleID'],\n    'Prediction': test_predicted_classes\n})\n\n# Save the predictions to a CSV file\ntest_predictions_df.to_csv('test_predictions__epochs.csv', index=False)\n\n# Print the predictions DataFrame\nprint(test_predictions_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T15:18:08.620530Z","iopub.execute_input":"2024-12-10T15:18:08.621581Z","iopub.status.idle":"2024-12-10T15:18:45.728976Z","shell.execute_reply.started":"2024-12-10T15:18:08.621526Z","shell.execute_reply":"2024-12-10T15:18:45.727884Z"}},"outputs":[{"name":"stdout","text":"0    [0.15690432488918304, -0.060619909316301346, 0...\n1    [0.3401837944984436, -0.2515227794647217, 0.17...\n2    [0.09620901942253113, -0.008898760192096233, -...\n3    [0.27392739057540894, -0.07054565101861954, 0....\n4    [0.19433511793613434, -0.1849549561738968, 0.2...\nName: Sentence_Embedding, dtype: object\n(10557, 1, 768)\n\u001b[1m  5/330\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 14ms/step   ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (32, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"       SampleID  Prediction\n0             1           3\n1             2           0\n2             3           1\n3             4           4\n4             5           3\n...         ...         ...\n10552     10553           4\n10553     10554           2\n10554     10555           3\n10555     10556           3\n10556     10557           3\n\n[10557 rows x 2 columns]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"test_predictions_df['Prediction'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T15:18:45.730600Z","iopub.execute_input":"2024-12-10T15:18:45.730940Z","iopub.status.idle":"2024-12-10T15:18:45.739611Z","shell.execute_reply.started":"2024-12-10T15:18:45.730907Z","shell.execute_reply":"2024-12-10T15:18:45.738512Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Prediction\n4    2423\n3    2407\n2    2187\n1    1775\n0    1765\nName: count, dtype: int64"},"metadata":{}}],"execution_count":15}]}